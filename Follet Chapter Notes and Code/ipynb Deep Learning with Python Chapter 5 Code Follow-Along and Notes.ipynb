{"cells":[{"cell_type":"markdown","source":["## \"Deep Learning with Python Chapter 5 Notes and Follow-Along Code\"\n","#### *Notebook created by: Jacob Kreider*\n"," This notebook covers *Chapter 5: Deep Learning for Computer Vison* from\n"," *Deep Learning with Python* by Francois Chollet, published by Manning\n"," Publications, 2018.<br/><br/>\n","### Chapter Topics:\n"," * Undertanding convolutional neural networks (hereafter, covnets)\n"," * Using data augmentation to mitigate overfitting\n"," * Using a pretrained covnet to do feature extraction\n"," * Fine-tuning a pretrained covnet\n"," * Visualizing what covnets learn and how they make classification decisions\n","### 5.1 : Introduction to covnets\n"," The code starts with creating and training a covnet on the MNIST dataset,\n"," which we used in Chapter 2. Back then, we used a *densely connected network*\n"," and achieved a test accuracy of 97.8%. <br/><br/>\n"," Here, we'll use a stack of *Conv2D* and *MaxPooling2D* layers to improve\n"," on that test accuracy."],"metadata":{}},{"source":["# Instantiating a small covnet\n","\n","from keras import layers\n","from keras import models\n","\n","model = models.Sequential()\n","model.add(layers.Conv2D(32, (3, 3), activation = 'relu'\n","                                  , input_shape = (28, 28, 1)))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" Covnets take input tensors of shape (height, width, channels), so we configured\n"," the covnet to take inputs of size (28, 28, 1), which is the format of our images\n"," in the MNIST database."],"metadata":{}},{"source":["# Displaying our covnet architecture:\n","\n","model.summary() \n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" In the above output, the output of each layer is a 3D tensor with the same\n"," shape as our inputs; however, the width and height dimensions shrink\n"," at each subsequent layer. The number of channels is controlled by the\n"," first argument passed (in this model, wither 32 or 64 channels). <br/><br/>\n","\n"," Next, we'll add some layers that feed the final output tensor into a\n"," densely connected classifier network (like the ones we created in\n"," chapters 2 and 3.)"],"metadata":{}},{"source":["# Adding a classifier on top of the covnet\n","\n","model.add(layers.Flatten())\n","model.add(layers.Dense(64, activation = 'relu'))\n","model.add(layers.Dense(10, activation = 'softmax'))\n","\n","model.summary()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Npw, we train the above covnet on the MNIST digits. Much of the \n","# following code is the same as Chapter 2\n","\n","from keras.datasets import mnist\n","from keras.utils import to_categorical\n","\n","(trainImages, trainLabels), (testImages, testLabels) = mnist.load_data()\n","\n","# reshape and retype the training and test data\n","trainImages = trainImages.reshape((60000, 28, 28, 1))\n","trainImages = trainImages.astype('float32') / 255\n","\n","testImages = testImages.reshape((10000, 28, 28, 1))\n","testImages = testImages.astype('float32') / 255\n","\n","trainLabels = to_categorical(trainLabels)\n","testLabels = to_categorical(testLabels)\n","\n","# Select the optimizer, loss function, and success metrics for evaluation\n","model.compile(optimizer = 'rmsprop'\n","             , loss = 'categorical_crossentropy'\n","             , metrics = ['accuracy'])\n","\n","# Fit the model\n","model.fit(trainImages, trainLabels, epochs=5, batch_size=64)\n","\n","# Evaluate on the test data\n","testLoss, testAcc = model.evaluate(testImages, testLabels)\n","\n","testAcc\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":["#### 5.1.1 The convolution operation\n"," How did adding the convnet to our network increase accuracy by 1.5\n"," absolute percentage points? <br/><br/>\n"," ***The funadmental difference between a densely connected layer and a\n"," convolutional layer is that Dense layers learn global patterns, while\n"," convolutional layers learn local patterns*** <br/><br/>\n","\n"," Two interesting properties arise from this charcteristic:\n"," * The patterns they learn are \"translation invariant\"\n"," * They can learn spatial hierarchies of patterns.\n","\n","\n"," Translation invariant means that once the network learns a pattern\n"," anywhere, it can recognize it *everywhere*. This allows the network\n"," to learn on fewer training examples and generalize what they find.\n","\n","\n"," A first convolutional layer will learn small, local patters, while the\n"," next layer will learn larger patterns made up of those smaller patterns.\n"," Continuing this through the layers allows the network to learn\n"," extremely complex and abstract patterns.\n","\n","#### Two key paraneters defining convolutions:\n"," * Size of the patches etracted from the inputs\n"," * Depth of the output feature map\n","\n","\n"," *Size of the patches* : the convolution operation extracts patches from\n"," its input feature map and applies the same transformation to all of them.\n"," This creates the *output feature map*. Common choices here are either\n"," 3x3 or 5x5 patches. Depth doesn't matter.\n","\n","\n"," *Depth of the output feaure map* : The number of *filters* computed by\n"," the convolution. Once the input channels have been converted into an\n"," output feature map, the depth axis no longer stands for, say, specific\n"," RGB colors, they now stand for filters. Filters encode specific aspects\n"," of the input data (e.g \"presence of a face\")\n","#### What does a convolution do?\n","\n"," A convolution slides the window size (of the patch, 3x3, 5x5, etc) over\n"," the entire 3D input and extracting the features at each possible point.\n"," Each 3D patch is then transformed by the *convolutional kernel* (by\n"," tensor product with the same learned weight matrix) into a 1D vector of\n"," shape(outputDepth). Then, all of these vectors are reassembled into the\n"," 3D output map. <br/>\n","\n"," Output width nd height often differ from input width and height due to\n"," *boarder effects* and the use of *strides*\n","\n","#### Understanding border effects and padding\n"," When the input feature map and the patch size create areas of the input\n"," the can't be mapped, the output width/height has to shrink. (For instance,\n"," a 5x5 input map only has 9 tiles that a 3x3 patch can be centered on.)\n"," <br/>\n","\n"," To counter this effect, you can use *padding*-- essentially, you add\n"," the rows and columns necessary to ensure that all input tiles can be\n"," mapped. (In keras, this is done via the padding argument, which defaults\n"," to 'valid' (no padding) and can be set to 'same' (adds padding).) <br/>\n","\n","#### Understanding convolutional strides\n"," The stride is the distance between two succesive windows when mapping\n"," with patches. The default is set at 1 (the center tiles of the\n"," convolution are all contiguous), but can be set higher. This is rarely\n"," done in practice.\n","\n","### 5.1.2 The max-pooling operation\n","\n"," The role of max pooling is to \"*aggressively downsample feature maps*\"\n"," <br/>\n","\n"," Max pooling works similarly to convolution, except that it: 1) local\n"," patches are transfored using a max tensor operation instead of the\n"," convolution kernel; 2) They are usually done with 2x2 windows; and,\n"," 3) they usually have stride 2. <br/>\n","\n"," Why downsample?\n"," * Reduces the number of coefficients to process\n"," * Induces spatial-filter hierarchies by making successive layers look\n"," at larger windows\n"," * Max pooling specifically works well because the max presence of features\n"," is more informative than the average presence"],"metadata":{}},{"source":[""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}