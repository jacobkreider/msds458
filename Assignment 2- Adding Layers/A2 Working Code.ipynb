{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VSAJFp6ItDAf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CacKZxD1tE61"
   },
   "source": [
    "Starting with Dr Maren code as the base. Then going to split it apart below and reshape to give outputs I'm looking for\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SVcXg4xhZEcH"
   },
   "outputs": [],
   "source": [
    "from random import seed\n",
    "import random\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(r\"D:\\MSDS-git\\msds458\\Data\")\n",
    "import csv\n",
    "\n",
    "# We want to use the exp function (e to the x); \n",
    "# it's part of our transfer function definition\n",
    "from math import exp\n",
    "\n",
    "# Biting the bullet and starting to use NumPy for arrays\n",
    "import numpy as np\n",
    "\n",
    "# So we can make a separate list from an initial one\n",
    "import copy\n",
    "\n",
    "# For pretty-printing the arrays\n",
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(suppress=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dpkUtOUp_Jbf"
   },
   "outputs": [],
   "source": [
    "# Some \"worker function\" that eist for specific tasks\n",
    "# Compute neuron activation using sigmoid transfer function\n",
    "def computeTransferFnctn(summedNeuronInput, alpha):\n",
    "    activation = 1.0 / (1.0 + exp(-alpha*summedNeuronInput)) \n",
    "    return activation\n",
    "    \n",
    "# Compute derivative of transfer function\n",
    "def computeTransferFnctnDeriv(NeuronOutput, alpha):\n",
    "    return alpha*NeuronOutput*(1.0 -NeuronOutput)     \n",
    "\n",
    "\n",
    "def matrixDotProduct (matrx1,matrx2):\n",
    "    dotProduct = np.dot(matrx1,matrx2)\n",
    "    \n",
    "    return(dotProduct) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-T2SLVrg_Jx9"
   },
   "outputs": [],
   "source": [
    "# Function to obtain the neural network size specifications\n",
    "\n",
    "def obtainNeuralNetworkSizeSpecs (): \n",
    "    # Define params for GB1 subnet\n",
    "    GB1numInputNodes = 81\n",
    "    GB1numHiddenNodes = 6\n",
    "    GB1numOutputNodes = 9  \n",
    "    \n",
    "    # Define params for full network\n",
    "    numInputNodes = 90\n",
    "    numHiddenNodes = 6\n",
    "    numOutputNodes = 9\n",
    "    \n",
    "    print()\n",
    "    print(\"  The number of nodes at each level are:\")\n",
    "    print(\"    Input: 9x9 (square array)\")\n",
    "    print(\"    Hidden: \", numHiddenNodes)\n",
    "    print(\"    Output: \", numOutputNodes)\n",
    "            \n",
    "# We create a list containing the crucial SIZES for the connection weight arrays                \n",
    "    arraySizeList = (GB1numInputNodes, GB1numHiddenNodes, GB1numOutputNodes\n",
    "                     , numInputNodes, numHiddenNodes, numOutputNodes)\n",
    "    \n",
    "# We return this list to the calling procedure, 'main'.       \n",
    "    return (arraySizeList)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_3ylsOod_J9S"
   },
   "outputs": [],
   "source": [
    "# Function to initialize a specific connection weight with a randomly-generated \n",
    "# number between 0 & 1\n",
    "\n",
    "def InitializeWeight ():\n",
    "\n",
    "    randomNum = random.random()\n",
    "    weight=1-2*randomNum\n",
    "#    print weight\n",
    "           \n",
    "    return (weight) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kqfSikBc_KHI"
   },
   "outputs": [],
   "source": [
    "# Function to initialize the node-to-node connection weight arrays\n",
    "\n",
    "def initializeWeightArray (weightArraySizeList):\n",
    "    numLowerNodes = weightArraySizeList[0] \n",
    "    numUpperNodes = weightArraySizeList[1] \n",
    "   \n",
    "    weightArray = np.zeros((numUpperNodes,numLowerNodes))    # iniitalize the weight matrix with 0's\n",
    "    for row in range(numUpperNodes):  #  Number of rows in weightMatrix\n",
    "        # For an input-to-hidden weight matrix, the rows correspond to the number of hidden nodes\n",
    "        #    and the columns correspond to the number of input nodes.\n",
    "        #    This creates an HxI matrix, which can be multiplied by the input matrix (expressed as a column)\n",
    "        # Similarly, for a hidden-to-output matrix, the rows correspond to the number of output nodes.\n",
    "        for col in range(numLowerNodes):  # number of columns in matrix 2\n",
    "            weightArray[row,col] = InitializeWeight ()                 \n",
    "         \n",
    "    return (weightArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VKXQlvwt_KQ2"
   },
   "outputs": [],
   "source": [
    "# Function to initialize the bias weight arrays\n",
    "\n",
    "def initializeBiasWeightArray (numBiasNodes):\n",
    "    biasWeightArray = np.zeros(numBiasNodes)    # iniitalize the weight matrix with 0's\n",
    "    for node in range(numBiasNodes):  #  Number of nodes in bias weight set\n",
    "        biasWeightArray[node] = InitializeWeight ()\n",
    "      \n",
    "    return (biasWeightArray) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "msjrTbl7AgbQ"
   },
   "outputs": [],
   "source": [
    "# Function to return a trainingDataList\n",
    "\n",
    "def obtainSelectedAlphabetTrainingValues (dataSet):\n",
    "    \n",
    "# Note: Nine possible output classes: 0 .. 8 trainingDataListXX [4]    \n",
    "    trainingDataListA0 =  (1,[0,0,0,0,1,0,0,0,0, 0,0,0,1,0,1,0,0,0, 0,0,1,0,0,0,1,0,0\n",
    "                              , 0,1,0,0,0,0,0,1,0, 1,1,1,1,1,1,1,1,1, 1,0,0,0,0,0,0,0,1\n",
    "                              , 1,0,0,0,0,0,0,0,1, 1,0,0,0,0,0,0,0,1, 1,0,0,0,0,0,0,0,1]\n",
    "                           ,1,'A',0,'A') \n",
    "    trainingDataListB0 =  (2,[1,1,1,1,1,1,1,1,0, 1,0,0,0,0,0,0,0,1, 1,0,0,0,0,0,0,0,1\n",
    "                              , 1,0,0,0,0,0,0,1,0, 1,1,1,1,1,1,1,0,0, 1,0,0,0,0,0,0,1,0\n",
    "                              , 1,0,0,0,0,0,0,0,1, 1,0,0,0,0,0,0,0,1, 1,1,1,1,1,1,1,1,0]\n",
    "                           ,2,'B',1,'B') \n",
    "    trainingDataListC0 =  (3,[1,1,1,1,1,1,1,1,1, 1,0,0,0,0,0,0,0,0, 1,0,0,0,0,0,0,0,0\n",
    "                              , 1,0,0,0,0,0,0,0,0, 1,0,0,0,0,0,0,0,0, 1,0,0,0,0,0,0,0,0\n",
    "                              , 1,0,0,0,0,0,0,0,0, 1,0,0,0,0,0,0,0,0, 1,1,1,1,1,1,1,1,1]\n",
    "                           ,3,'C',2,'C') \n",
    "    trainingDataListD0 =  (4,[1,1,1,1,1,1,1,1,0, 1,0,0,0,0,0,0,1,1, 1,0,0,0,0,0,0,0,1\n",
    "                              , 1,0,0,0,0,0,0,0,1, 1,0,0,0,0,0,0,0,1, 1,0,0,0,0,0,0,0\n",
    "                              ,1, 1,0,0,0,0,0,0,0,1, 1,0,0,0,0,0,0,1,1, 1,1,1,1,1,1,1\n",
    "                              ,1,0],4,'D',3,'O') \n",
    "    trainingDataListE0 =  (5,[1,1,1,1,1,1,1,1,1, 1,0,0,0,0,0,0,0,0, 1,0,0,0,0,0,0,0,0\n",
    "                              , 1,0,0,0,0,0,0,0,0, 1,1,1,1,1,1,1,1,1, 1,0,0,0,0,0,0,0\n",
    "                              ,0, 1,0,0,0,0,0,0,0,0, 1,0,0,0,0,0,0,0,0, 1,1,1,1,1,1,1\n",
    "                              ,1,1],5,'E',4,'E') \n",
    "    trainingDataListF0 =  (6,[1,1,1,1,1,1,1,1,1, 1,0,0,0,0,0,0,0,0, 1,0,0,0,0,0,0,0,0\n",
    "                              , 1,0,0,0,0,0,0,0,0, 1,1,1,1,1,1,1,1,1, 1,0,0,0,0,0,0,0\n",
    "                              ,0, 1,0,0,0,0,0,0,0,0, 1,0,0,0,0,0,0,0,0, 1,0,0,0,0,0,0\n",
    "                              ,0,0],6,'F',4,'E') \n",
    "    trainingDataListG0 =  (7,[1,1,1,1,1,1,1,1,1, 1,0,0,0,0,0,0,0,0, 1,0,0,0,0,0,0,0,0\n",
    "                              , 1,0,0,0,0,0,0,0,0, 1,0,0,0,0,0,0,0,0, 1,0,0,0,0,0,1,1\n",
    "                              ,1, 1,0,0,0,0,0,0,0,1, 1,0,0,0,0,0,0,0,1, 1,1,1,1,1,1,1\n",
    "                              ,1,1],7,'G',1,'C')\n",
    "    trainingDataListH0 =  (8,[1,0,0,0,0,0,0,0,1, 1,0,0,0,0,0,0,0,1, 1,0,0,0,0,0,0,0,1\n",
    "                              , 1,0,0,0,0,0,0,0,1, 1,1,1,1,1,1,1,1,1, 1,0,0,0,0,0,0,0\n",
    "                              ,1, 1,0,0,0,0,0,0,0,1, 1,0,0,0,0,0,0,0,1, 1,0,0,0,0,0,0\n",
    "                              ,0,1],8,'H',0,'A') \n",
    "    trainingDataListI0 =  (9,[0,0,1,1,1,1,1,0,0, 0,0,0,0,1,0,0,0,0, 0,0,0,0,1,0,0,0,0\n",
    "                              , 0,0,0,0,1,0,0,0,0, 0,0,0,0,1,0,0,0,0, 0,0,0,0,1,0,0,0\n",
    "                              ,0, 0,0,0,0,1,0,0,0,0, 0,0,0,0,1,0,0,0,0, 0,0,1,1,1,1,1\n",
    "                              ,0,0],9,'I',5,'I') \n",
    "    trainingDataListJ0 = (10,[0,0,0,0,0,0,0,1,0, 0,0,0,0,0,0,0,1,0, 0,0,0,0,0,0,0,1,0\n",
    "                              , 0,0,0,0,0,0,0,1,0, 0,0,0,0,0,0,0,1,0, 0,1,0,0,0,0,0,1\n",
    "                              ,0, 0,1,0,0,0,0,0,1,0, 0,0,1,0,0,0,1,0,0, 0,0,0,1,1,1,0\n",
    "                              ,0,0],10,'J',5,'I') \n",
    "    trainingDataListK0 = (11,[1,0,0,0,0,0,1,0,0, 1,0,0,0,0,1,0,0,0, 1,0,0,0,1,0,0,0,0\n",
    "                              , 1,0,0,1,0,0,0,0,0, 1,1,1,0,0,0,0,0,0, 1,0,0,1,0,0,0,0\n",
    "                              ,0, 1,0,0,0,1,0,0,0,0, 1,0,0,0,0,1,0,0,0, 1,0,0,0,0,0,1\n",
    "                              ,0,0],11,'K',6,'K')    \n",
    "    trainingDataListL0 = (12,[1,0,0,0,0,0,0,0,0, 1,0,0,0,0,0,0,0,0, 1,0,0,0,0,0,0,0,0\n",
    "                              , 1,0,0,0,0,0,0,0,0, 1,0,0,0,0,0,0,0,0, 1,0,0,0,0,0,0,0\n",
    "                              ,0, 1,0,0,0,0,0,0,0,0, 1,0,0,0,0,0,0,0,0, 1,1,1,1,1,1,1\n",
    "                              ,1,1],12,'L',7,'L') \n",
    "    trainingDataListM0 = (13,[1,0,0,0,0,0,0,0,1, 1,1,0,0,0,0,0,1,1, 1,1,0,0,0,0,0,1,1\n",
    "                              , 1,0,1,0,0,0,1,0,1, 1,0,1,0,0,0,1,0,1, 1,0,0,1,0,1,0,0\n",
    "                              ,1, 1,0,0,1,0,1,0,0,1, 1,1,0,0,1,0,0,0,1, 1,0,0,0,1,0,0\n",
    "                              ,0,1],13,'M',8,'M')            \n",
    "    trainingDataListN0 = (14,[1,0,0,0,0,0,0,0,1, 1,1,0,0,0,0,0,0,1, 1,0,1,0,0,0,0,0,1\n",
    "                              , 1,0,0,1,0,0,0,0,1, 1,0,0,0,1,0,0,0,1, 1,0,0,0,0,1,0,0\n",
    "                              ,1, 1,0,0,0,0,0,1,0,1, 1,0,0,0,0,0,0,1,1, 1,0,0,0,0,0,0\n",
    "                              ,0,1],14,'N',8,'M') \n",
    "    trainingDataListO0 = (15,[0,1,1,1,1,1,1,1,0, 1,1,0,0,0,0,0,1,1, 1,0,0,0,0,0,0,0,1\n",
    "                              , 1,0,0,0,0,0,0,0,1, 1,0,0,0,0,0,0,0,1, 1,0,0,0,0,0,0,0\n",
    "                              ,1, 1,0,0,0,0,0,0,0,1, 1,0,0,0,0,0,0,0,1, 0,1,1,1,1,1,1\n",
    "                              ,1,0],15,'O',3,'O') \n",
    "    trainingDataListP0 = (16,[1,1,1,1,1,1,1,1,1, 1,0,0,0,0,0,0,0,1, 1,0,0,0,0,0,0,0,1\n",
    "                              , 1,0,0,0,0,0,0,0,1, 1,1,1,1,1,1,1,1,1, 1,0,0,0,0,0,0,0\n",
    "                              ,0, 1,0,0,0,0,0,0,0,0, 1,0,0,0,0,0,0,0,0, 1,0,0,0,0,0,0\n",
    "                              ,0,0],16,'P',1, 'B') \n",
    "\n",
    "\n",
    "    if dataSet == 1: trainingDataList = trainingDataListA0\n",
    "    if dataSet == 2: trainingDataList = trainingDataListB0 \n",
    "    if dataSet == 3: trainingDataList = trainingDataListC0\n",
    "    if dataSet == 4: trainingDataList = trainingDataListD0     \n",
    "    if dataSet == 5: trainingDataList = trainingDataListE0\n",
    "    if dataSet == 6: trainingDataList = trainingDataListF0 \n",
    "    if dataSet == 7: trainingDataList = trainingDataListG0 \n",
    "    if dataSet == 8: trainingDataList = trainingDataListH0\n",
    "    if dataSet == 9: trainingDataList = trainingDataListI0\n",
    "    if dataSet == 10: trainingDataList = trainingDataListJ0    \n",
    "\n",
    "    if dataSet == 11: trainingDataList = trainingDataListK0 \n",
    "    if dataSet == 12: trainingDataList = trainingDataListL0\n",
    "    if dataSet == 13: trainingDataList = trainingDataListM0\n",
    "    if dataSet == 14: trainingDataList = trainingDataListN0 \n",
    "    if dataSet == 15: trainingDataList = trainingDataListO0 \n",
    "    if dataSet == 16: trainingDataList = trainingDataListP0  \n",
    "\n",
    "                           \n",
    "    return (trainingDataList)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pc08IcqjE-wf"
   },
   "source": [
    "### Feedforward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4kxVQ5pgeDyT"
   },
   "outputs": [],
   "source": [
    "def ComputeGB1SingleFeedforwardPassFirstStep (alpha, GB1inputDataArray\n",
    "                                              , GB1wWeightArray, GB1wBiasWeightArray):         \n",
    "# iniitalize the sum of inputs into the hidden array with 0's  \n",
    "    GB1sumIntoHiddenArray = np.zeros(GB1hiddenArrayLength)    \n",
    "    GB1hiddenArray = np.zeros(GB1hiddenArrayLength)   \n",
    "\n",
    "    GB1sumIntoHiddenArray = matrixDotProduct (GB1wWeightArray,GB1inputDataArray)\n",
    "    \n",
    "    for node in range(GB1hiddenArrayLength):  #  Number of hidden nodes\n",
    "        GB1hiddenNodeSumInput=GB1sumIntoHiddenArray[node]+GB1wBiasWeightArray[node]\n",
    "        GB1hiddenArray[node] = computeTransferFnctn(GB1hiddenNodeSumInput, alpha)\n",
    "\n",
    "#    print ' '\n",
    "#    print 'Back in ComputeSingleFeedforwardPass'\n",
    "#    print 'The activations for the hidden nodes are:'\n",
    "#    print '  Hidden0 = %.4f' % hiddenActivation0, 'Hidden1 = %.4f' % hiddenActivation1\n",
    "\n",
    "                                                                                                    \n",
    "    return (GB1hiddenArray);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeSingleFeedforwardPassFirstStep (alpha, inputDataList, wWeightArray, biasHiddenWeightArray):\n",
    "    \n",
    "# iniitalize the sum of inputs into the hidden array with 0's  \n",
    "    sumIntoHiddenArray = np.zeros(hiddenArrayLength)    \n",
    "    hiddenArray = np.zeros(hiddenArrayLength)   \n",
    "\n",
    "    sumIntoHiddenArray = matrixDotProduct (wWeightArray,inputDataList)\n",
    "    \n",
    "    for node in range(hiddenArrayLength):  #  Number of hidden nodes\n",
    "        hiddenNodeSumInput=sumIntoHiddenArray[node]+biasHiddenWeightArray[node]\n",
    "        hiddenArray[node] = computeTransferFnctn(hiddenNodeSumInput, alpha)\n",
    "\n",
    "#    print ' '\n",
    "#    print 'Back in ComputeSingleFeedforwardPass'\n",
    "#    print 'The activations for the hidden nodes are:'\n",
    "#    print '  Hidden0 = %.4f' % hiddenActivation0, 'Hidden1 = %.4f' % hiddenActivation1\n",
    "\n",
    "                                                                                                    \n",
    "    return (hiddenArray);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeSingleFeedforwardPassSecondStep (alpha, hiddenArray, vWeightArray, biasOutputWeightArray):\n",
    "    \n",
    "# initialize the sum of inputs into the hidden array with 0's  \n",
    "    sumIntoOutputArray = np.zeros(hiddenArrayLength)    \n",
    "    outputArray = np.zeros(outputArrayLength)   \n",
    "\n",
    "    sumIntoOutputArray = matrixDotProduct (vWeightArray,hiddenArray)\n",
    "    \n",
    "    for node in range(outputArrayLength):  #  Number of hidden nodes\n",
    "        outputNodeSumInput=sumIntoOutputArray[node]+biasOutputWeightArray[node]\n",
    "        outputArray[node] = computeTransferFnctn(outputNodeSumInput, alpha)\n",
    "                                                                                                   \n",
    "    return (outputArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xe1MRrWed5V5"
   },
   "outputs": [],
   "source": [
    "def ComputeGB1SingleFeedforwardPassSecondStep (alpha, GB1hiddenArray, GB1vWeightArray, GB1vBiasWeightArray):\n",
    "    \n",
    "# initialize the sum of inputs into the hidden array with 0's  \n",
    "    GB1sumIntoOutputArray = np.zeros(GB1hiddenArrayLength)    \n",
    "    GB1outputArray = np.zeros(GB1outputArrayLength)   \n",
    "\n",
    "    GB1sumIntoOutputArray = matrixDotProduct (GB1vWeightArray,GB1hiddenArray)\n",
    "    \n",
    "    for node in range(GB1outputArrayLength):  #  Number of hidden nodes\n",
    "        GB1outputNodeSumInput=GB1sumIntoOutputArray[node]+GB1vBiasWeightArray[node]\n",
    "        GB1outputArray[node] = computeTransferFnctn(GB1outputNodeSumInput, alpha)\n",
    "                                                                                                   \n",
    "    return (GB1outputArray);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e_U-w2jCB7qT"
   },
   "source": [
    "For the ComputeOutputsAcrossAllTrainingData in the next section, I actually call this outside of\n",
    "a function in a later section-- I never actually use the function. \n",
    "\n",
    "I found it easier to get the returns I wanted outside of a function call-- the same reason I did away with\n",
    "the 'Main' procedure. Obviously not what you want to do for production work, but for this it made my life a bit easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xyXgCJyzAgq2"
   },
   "outputs": [],
   "source": [
    "# Procedure to compute the output node activations and determine errors across the entire training\n",
    "#  data set, and print results.\n",
    "\n",
    "def ComputeOutputsAcrossAllTrainingData (alpha, numTrainingDataSets, wWeightArray, \n",
    "biasHiddenWeightArray, vWeightArray, biasOutputWeightArray, GB1wWeightArray, GB1wBiasWeightArray, \n",
    "GB1vWeightArray, GB1vBiasWeightArray):\n",
    "\n",
    "    selectedTrainingDataSet = 1                              \n",
    "                              \n",
    "\n",
    "    while selectedTrainingDataSet < numTrainingDataSets + 1: \n",
    "\n",
    "        trainingDataList = obtainSelectedAlphabetTrainingValues (selectedTrainingDataSet)\n",
    "# Note: the trainingDataList is a list comprising several values:\n",
    "#    - the 0th is the list number \n",
    "#    - the 1st is the actual list of the input training values\n",
    "#    - etc. \n",
    "\n",
    "\n",
    "        trainingDataInputList = trainingDataList[1]      \n",
    "\n",
    "# Obtain the outputs from GB1\n",
    "            \n",
    "        GB1inputDataList = [] \n",
    "        GB1inputDataArray = np.zeros(GB1inputArrayLength) \n",
    "        for node in range(GB1inputArrayLength): \n",
    "            trainingData = trainingDataInputList[node]  \n",
    "            GB1inputDataList.append(trainingData)\n",
    "            GB1inputDataArray[node] = trainingData\n",
    "\n",
    "#        print ' ' \n",
    "#        print ' before running Grey Box 1'\n",
    "        GB1hiddenArray = ComputeGB1SingleFeedforwardPassFirstStep (alpha, GB1inputDataArray\n",
    "                                                                   , GB1wWeightArray, GB1wBiasWeightArray)\n",
    "        GB1outputArray = ComputeGB1SingleFeedforwardPassSecondStep (alpha, GB1hiddenArray\n",
    "                                                                    , GB1vWeightArray, GB1vBiasWeightArray)                        \n",
    "#        print ' after running Grey Box 1'\n",
    "#        print ' ' \n",
    "\n",
    "\n",
    "\n",
    "# Obtain the outputs from the full multi-component network\n",
    "\n",
    "# First, obtain a full input vector\n",
    "        inputDataList = [] \n",
    "        inputDataArray = np.zeros(inputArrayLength) \n",
    "\n",
    "#        print ' ' \n",
    "#        print ' about to create training data for the multicomponent network'        \n",
    "# Fill the first part of the training data list with the usual inputs\n",
    "        for node in range(GB1inputArrayLength): \n",
    "            trainingData = trainingDataInputList[node]  \n",
    "            inputDataList.append(trainingData)\n",
    "#        print ' first part inputDataList:'\n",
    "#        print inputDataList\n",
    "\n",
    "# Fill the second part of the training data list with the outputs from GB1          \n",
    "        for node in range(GB1outputArrayLength): \n",
    "            trainingData = GB1outputArray[node]  \n",
    "            inputDataList.append(trainingData)\n",
    "#        print ' ' \n",
    "#        print ' the whole inputDataList'\n",
    "#        print inputDataList          \n",
    "\n",
    "# Create an input array with both the original training data and the outputs from GB1\n",
    "        for node in range(inputArrayLength): \n",
    "            inputDataArray[node] = inputDataList[node]            \n",
    "#        print ' ' \n",
    "#        print ' the whole inputDataArray'\n",
    "#        print inputDataArray\n",
    "        \n",
    "        letterNum = trainingDataList[2] +1\n",
    "        letterChar = trainingDataList[3]  \n",
    "        print (' ')\n",
    "        print ('  Data Set Number', selectedTrainingDataSet, ' for letter ', letterChar\n",
    "               , ' with letter number ', letterNum) \n",
    "\n",
    "        hiddenArray = ComputeSingleFeedforwardPassFirstStep (alpha, inputDataArray\n",
    "                                                             , wWeightArray, biasHiddenWeightArray)\n",
    "\n",
    "        print (' ')\n",
    "        print (' The hidden node activations are:')\n",
    "        print (hiddenArray)\n",
    "\n",
    "        outputArray = ComputeSingleFeedforwardPassSecondStep (alpha, hiddenArray\n",
    "                                                              , vWeightArray, biasOutputWeightArray)\n",
    "    \n",
    "        print (' ')\n",
    "        print (' The output node activations are:')\n",
    "        print (outputArray)   \n",
    "\n",
    "        desiredOutputArray = np.zeros(outputArrayLength) # iniitalize the output array with 0's\n",
    "        desiredClass = trainingDataList[4]                 # identify the desired class number\n",
    "        print()\n",
    "        print('Desired Class Number is:  ', desiredClass)\n",
    "        print()\n",
    "        desiredOutputArray[desiredClass] = 1                # set the desired output for that class to 1\n",
    "     \n",
    "        print (' ')\n",
    "        print (' The desired output array values are: ')\n",
    "        print (desiredOutputArray)  \n",
    "       \n",
    "                        \n",
    "# Determine the error between actual and desired outputs\n",
    "\n",
    "# Initialize the error array\n",
    "        errorArray = np.zeros(outputArrayLength) \n",
    "    \n",
    "        newSSE = 0.0\n",
    "        for node in range(outputArrayLength):  #  Number of nodes in output set (classes)\n",
    "            errorArray[node] = desiredOutputArray[node] - outputArray[node]\n",
    "            newSSE = newSSE + errorArray[node]*errorArray[node]        \n",
    "\n",
    "        print (' ')\n",
    "        print (' The error values are:')\n",
    "        print (errorArray)   \n",
    "        \n",
    "# Print the Summed Squared Error  \n",
    "        print ('New SSE = %.6f' % newSSE) \n",
    "         \n",
    "        selectedTrainingDataSet = selectedTrainingDataSet +1 \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pcwU9hylCfOo"
   },
   "source": [
    "### Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9j7OXyOwAg16"
   },
   "outputs": [],
   "source": [
    "# Backpropagate weight changes onto the hidden-to-output connection weights\n",
    "\n",
    "def backpropagateOutputToHidden (alpha, eta, arraySizeList, errorArray, outputArray, hiddenArray, vWeightArray):\n",
    "\n",
    "# Unpack array lengths\n",
    "    hiddenArrayLength = arraySizeList [4]\n",
    "    outputArrayLength = arraySizeList [5]\n",
    "\n",
    "    transferFuncDerivArray = np.zeros(outputArrayLength)    \n",
    "      \n",
    "    for node in range(outputArrayLength):  #  Number of hidden nodes\n",
    "        transferFuncDerivArray[node]=computeTransferFnctnDeriv(outputArray[node], alpha)\n",
    "                        \n",
    "    deltaVWtArray = np.zeros((outputArrayLength, hiddenArrayLength))  # initialize an array for the deltas\n",
    "    newVWeightArray = np.zeros((outputArrayLength, hiddenArrayLength)) # initialize an array for the new hidden weights\n",
    "        \n",
    "    for row in range(outputArrayLength):  #  Number of rows in weightMatrix\n",
    "\n",
    "        for col in range(hiddenArrayLength):  # number of columns in weightMatrix\n",
    "            partialSSE_w_V_Wt = -errorArray[row]*transferFuncDerivArray[row]*hiddenArray[col]\n",
    "            deltaVWtArray[row,col] = -eta*partialSSE_w_V_Wt\n",
    "            newVWeightArray[row,col] = vWeightArray[row,col] + deltaVWtArray[row,col]                                                                                        \n",
    "                                                                  \n",
    "                                                                                                                                                                                                            \n",
    "    return (newVWeightArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3UxImgqeAhAX"
   },
   "outputs": [],
   "source": [
    "# Backpropagate weight changes onto the bias-to-output connection weights\n",
    "\n",
    "def backpropagateBiasOutputWeights (alpha, eta, arraySizeList, errorArray, outputArray, biasOutputWeightArray):\n",
    "\n",
    "#  Unpack the output array length\n",
    "    outputArrayLength = arraySizeList [5]\n",
    "\n",
    "    deltaBiasOutputArray = np.zeros(outputArrayLength)  # initialize an array for the deltas\n",
    "    newBiasOutputWeightArray = np.zeros(outputArrayLength) # initialize an array for the new output bias weights\n",
    "    transferFuncDerivArray = np.zeros(outputArrayLength)    # iniitalize an array for the transfer function\n",
    "      \n",
    "    for node in range(outputArrayLength):  #  Number of hidden nodes\n",
    "        transferFuncDerivArray[node]=computeTransferFnctnDeriv(outputArray[node], alpha)\n",
    " \n",
    "\n",
    "    for node in range(outputArrayLength):  #  Number of nodes in output array (same as number of output bias nodes)    \n",
    "        partialSSE_w_BiasOutput = -errorArray[node]*transferFuncDerivArray[node]\n",
    "        deltaBiasOutputArray[node] = -eta*partialSSE_w_BiasOutput  \n",
    "        newBiasOutputWeightArray[node] =  biasOutputWeightArray[node] + deltaBiasOutputArray[node]           \n",
    "                                                                                                          \n",
    "    return (newBiasOutputWeightArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xV2U-CR8C8ST"
   },
   "outputs": [],
   "source": [
    "# Backpropagate weight changes onto the input-to-hidden connection weights\n",
    "\n",
    "def backpropagateHiddenToInput (alpha, eta, arraySizeList, errorArray, outputArray, hiddenArray,\n",
    "    inputArray, vWeightArray, wWeightArray, biasHiddenWeightArray, biasOutputWeightArray):\n",
    "\n",
    "# Unpack array lengths\n",
    "    inputArrayLength = arraySizeList [3]\n",
    "    hiddenArrayLength = arraySizeList [4]\n",
    "    outputArrayLength = arraySizeList [5]              \n",
    "                                          \n",
    "\n",
    "    transferFuncDerivHiddenArray = np.zeros(hiddenArrayLength)    \n",
    "    for node in range(hiddenArrayLength):  #  Number of hidden nodes\n",
    "        transferFuncDerivHiddenArray[node]=computeTransferFnctnDeriv(hiddenArray[node], alpha)\n",
    "        \n",
    "    errorTimesTFuncDerivOutputArray = np.zeros(outputArrayLength) # initialize array\n",
    "    transferFuncDerivOutputArray    = np.zeros(outputArrayLength) # initialize array\n",
    "    weightedErrorArray              = np.zeros(hiddenArrayLength) # initialize array\n",
    "      \n",
    "    for outputNode in range(outputArrayLength):  #  Number of output nodes\n",
    "        transferFuncDerivOutputArray[outputNode]=computeTransferFnctnDeriv(outputArray[outputNode], alpha)\n",
    "        errorTimesTFuncDerivOutputArray[outputNode] = errorArray[outputNode]*transferFuncDerivOutputArray[outputNode]\n",
    "        \n",
    "    for hiddenNode in range(hiddenArrayLength):\n",
    "        weightedErrorArray[hiddenNode] = 0\n",
    "        for outputNode in range(outputArrayLength):  #  Number of output nodes    \n",
    "            weightedErrorArray[hiddenNode] = weightedErrorArray[hiddenNode] \\\n",
    "            + vWeightArray[outputNode, hiddenNode]*errorTimesTFuncDerivOutputArray[outputNode]\n",
    "             \n",
    "    deltaWWtArray = np.zeros((hiddenArrayLength, inputArrayLength))  # initialize an array for the deltas\n",
    "    newWWeightArray = np.zeros((hiddenArrayLength, inputArrayLength)) # initialize an array for the new input-to-hidden weights\n",
    "        \n",
    "    for row in range(hiddenArrayLength):  \n",
    "\n",
    "        for col in range(inputArrayLength):  # number of columns in weightMatrix\n",
    "            partialSSE_w_W_Wts = -transferFuncDerivHiddenArray[row]*inputArray[col]*weightedErrorArray[row]\n",
    "            deltaWWtArray[row,col] = -eta*partialSSE_w_W_Wts\n",
    "            newWWeightArray[row,col] = wWeightArray[row,col] + deltaWWtArray[row,col]                                                                                     \n",
    "                                        \n",
    "    return (newWWeightArray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RFpqA5ptC8YV"
   },
   "outputs": [],
   "source": [
    "# Backpropagate weight changes onto the bias-to-hidden connection weights\n",
    "\n",
    "def backpropagateBiasHiddenWeights (alpha, eta, arraySizeList, errorArray, outputArray, hiddenArray,\n",
    "    inputArray, vWeightArray, wWeightArray, biasHiddenWeightArray, biasOutputWeightArray):\n",
    "# Unpack array lengths\n",
    "    inputArrayLength = arraySizeList [3]\n",
    "    hiddenArrayLength = arraySizeList [4]\n",
    "    outputArrayLength = arraySizeList [5]  \n",
    "               \n",
    "\n",
    "    errorTimesTFuncDerivOutputArray = np.zeros(outputArrayLength)    \n",
    "    transferFuncDerivOutputArray    = np.zeros(outputArrayLength) \n",
    "    weightedErrorArray              = np.zeros(hiddenArrayLength)    \n",
    "\n",
    "    transferFuncDerivHiddenArray = np.zeros(hiddenArrayLength)  \n",
    "    partialSSE_w_BiasHidden      = np.zeros(hiddenArrayLength)  \n",
    "    deltaBiasHiddenArray         = np.zeros(hiddenArrayLength)  \n",
    "    newBiasHiddenWeightArray     = np.zeros(hiddenArrayLength)  \n",
    "          \n",
    "    for node in range(hiddenArrayLength):  #  Number of hidden nodes\n",
    "        transferFuncDerivHiddenArray[node]=computeTransferFnctnDeriv(hiddenArray[node], alpha)      \n",
    "                  \n",
    "    for outputNode in range(outputArrayLength):  #  Number of output nodes\n",
    "        transferFuncDerivOutputArray[outputNode]=computeTransferFnctnDeriv(outputArray[outputNode], alpha) \n",
    "        errorTimesTFuncDerivOutputArray[outputNode] = errorArray[outputNode]*transferFuncDerivOutputArray[outputNode]\n",
    "\n",
    "    for hiddenNode in range(hiddenArrayLength):\n",
    "        weightedErrorArray[hiddenNode] = 0\n",
    "        for outputNode in range(outputArrayLength):  #  Number of output nodes    \n",
    "            weightedErrorArray[hiddenNode] = (weightedErrorArray[hiddenNode]\n",
    "            + vWeightArray[outputNode, hiddenNode]*errorTimesTFuncDerivOutputArray[outputNode])\n",
    "\n",
    "    for hiddenNode in range(hiddenArrayLength):  #  Number of rows in input-to-hidden weightMatrix           \n",
    "        partialSSE_w_BiasHidden[hiddenNode] = -transferFuncDerivHiddenArray[hiddenNode]*weightedErrorArray[hiddenNode]\n",
    "        deltaBiasHiddenArray[hiddenNode] = -eta*partialSSE_w_BiasHidden[hiddenNode]\n",
    "        newBiasHiddenWeightArray[hiddenNode] = biasHiddenWeightArray[hiddenNode] + deltaBiasHiddenArray[hiddenNode]                                                                                                                                                                                                                                                         \n",
    "  \n",
    "                                                                                                                                            \n",
    "    return (newBiasHiddenWeightArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding Grid Boundaries\n",
    "\n",
    "\"The following modules expand the boundaries around a chosen letter, and apply a masking filter to that expanded letter. The result is an array (9x9 in this case) of units, with activation values where 0 <= v <= 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to expand the grid containing a letter by one pixel in each direction\n",
    "\n",
    "def expandLetterBoundaries (trainingDataList):                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
    "    pixelArray = trainingDataList[1]\n",
    "\n",
    "\n",
    "    expandedLetterArray = np.zeros(shape=(eGH,eGW)) \n",
    "\n",
    "    iterAcrossRow = 0\n",
    "    iterOverAllRows = 0\n",
    "\n",
    "\n",
    "\n",
    "# For logical completeness: The first element of each row in the expanded letter is set to zero\n",
    "    iterAcrossRow = 0\n",
    "#    print ' Zeroth row:'\n",
    "    while iterAcrossRow < eGW:\n",
    "        expandedLetterArray[iterOverAllRows,iterAcrossRow] = 0  \n",
    "#        print iterAcrossRow, expandedLetterArray[iterOverAllRows,iterAcrossRow] \n",
    "        iterAcrossRow = iterAcrossRow + 1\n",
    "\n",
    "\n",
    "# Fill in the elements of the expandedLetterArray; rows 1 .. eGH-1\n",
    "    \n",
    "    rowVal = 1\n",
    "    while rowVal <eGH-1:\n",
    "#        print 'iterOverAllRows = ', iterOverAllRows\n",
    "\n",
    "# For the next gridWidth elements in the row, in the expanded letter is set to zero       \n",
    "        iterAcrossRow = 0\n",
    "        expandedLetterArray[iterOverAllRows,iterAcrossRow] = 0\n",
    "        \n",
    "        iterAcrossRow = 1       \n",
    "        while iterAcrossRow < eGW-1:\n",
    "            expandedLetterArray[rowVal,iterAcrossRow] = 0\n",
    "            #Note: We start counting in the pixelArray at iterAcrossRow-1, because that array \n",
    "            #      starts at with the first element at position '0'\n",
    "            #      and iterAcrossRow is one count beyond that \n",
    "            if pixelArray[iterAcrossRow-1+(rowVal-1)*gridWidth] > 0.9: \n",
    "                expandedLetterArray[rowVal,iterAcrossRow] = 1\n",
    "#            print iterAcrossRow, expandedLetterArray[iterOverAllRows,iterAcrossRow]\n",
    "            iterAcrossRow = iterAcrossRow +1\n",
    "#        print ' '\n",
    "        iterAcrossRow = 0  #re-initialize iteration count  \n",
    "        rowVal = rowVal +1\n",
    "\n",
    "        # For logical completeness: The last element of each row in the expanded letter is set to zero\n",
    "        # Note: The last element in the row is at position eGW-1, as the row count starts with 0\n",
    "    rowVal = eGH-1\n",
    "    iterAcrossRow = 0\n",
    "    while iterAcrossRow < eGW-1:\n",
    "        expandedLetterArray[rowVal,iterAcrossRow] = 0  \n",
    "#        print iterAcrossRow, expandedLetterArray[iterOverAllRows,iterAcrossRow] \n",
    "        iterAcrossRow = iterAcrossRow + 1      \n",
    "      \n",
    "#    print ' '    \n",
    "    return expandedLetterArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedure to print out a letter, given the number of the letter code\n",
    "\n",
    "def printLetter (trainingDataList):    \n",
    "\n",
    "    print (' ')\n",
    "    print (' in procedure printLetter')\n",
    "    print (' ')                         \n",
    "    print ('The training data set is ', trainingDataList[0])\n",
    "    print ('The data set is for the letter', trainingDataList[3], ', which is alphabet number ', trainingDataList[2])\n",
    "\n",
    "    if trainingDataList[0] > 25: (print('This is a variant pattern for letter ', trainingDataList[3])) \n",
    "\n",
    "    pixelArray = trainingDataList[1]\n",
    "                \n",
    "    iterAcrossRow = 0\n",
    "    iterOverAllRows = 0\n",
    "    while iterOverAllRows <gridHeight:\n",
    "        while iterAcrossRow < gridWidth:\n",
    "#            arrayElement = pixelArray [iterAcrossRow+iterOverAllRows*gridWidth]\n",
    "#            if arrayElement <0.9: printElement = ' '\n",
    "#            else: printElement = 'X'\n",
    "#            print printElement, \n",
    "            iterAcrossRow = iterAcrossRow+1\n",
    "#        print ' '\n",
    "        iterOverAllRows = iterOverAllRows + 1\n",
    "        iterAcrossRow = 0 #re-initialize so the row-print can begin again\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedure to print the expanded letter (with a one-pixel border of zeros around the original)  \n",
    "\n",
    "def printExpandedLetter (expandedLetterArray):                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
    "    print (' The expanded letter is:')\n",
    "    print (expandedLetterArray)   \n",
    "        \n",
    "           \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return the letterArray after mask1 has been applied to it\n",
    "\n",
    "def mask1LetterFunc(expandedLetterArray):\n",
    "\n",
    "    \n",
    "    mask1LetterArray = np.zeros(shape=(gridHeight,gridWidth))\n",
    "    \n",
    "   \n",
    "    rowVal = 1\n",
    "    colVal = 1\n",
    "        \n",
    "\n",
    "    while rowVal <gridHeight+1: \n",
    "\n",
    "        arrayRow = rowVal - 1 \n",
    "\n",
    "        while colVal <gridWidth+1:           \n",
    "            e0 =  expandedLetterArray[rowVal-1, colVal-1]\n",
    "            e1 =  expandedLetterArray[rowVal-1, colVal]\n",
    "            e2 =  expandedLetterArray[rowVal-1, colVal+1]   \n",
    "            e3 =  expandedLetterArray[rowVal, colVal-1]\n",
    "            e4 =  expandedLetterArray[rowVal, colVal]\n",
    "            e5 =  expandedLetterArray[rowVal, colVal+1]   \n",
    "            e6 =  expandedLetterArray[rowVal+1, colVal-1]\n",
    "            e7 =  expandedLetterArray[rowVal+1, colVal]\n",
    "            e8 =  expandedLetterArray[rowVal+1, colVal+1]               \n",
    "              \n",
    "            mask1ArrayVal    =  (e0*mask1[0] + e1*mask1[1] + e2*mask1[2] + \n",
    "                                e3*mask1[3] + e4*mask1[4] + e5*mask1[5] + \n",
    "                                e6*mask1[6] + e7*mask1[7] + e8*mask1[8] ) / 3.0                        \n",
    "                         \n",
    "            arrayCol = colVal - 1\n",
    "\n",
    "            mask1LetterArray[arrayRow,arrayCol] = mask1ArrayVal \n",
    "            colVal = colVal + 1\n",
    "\n",
    "        rowVal = rowVal + 1\n",
    "        colVal = 1\n",
    "\n",
    "                                        \n",
    "    return mask1LetterArray "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedure to convert the 2x2 array produced by maskLetter into a list and return the list \n",
    "\n",
    "def convertArrayToList(mask1LetterArray):\n",
    "\n",
    "    mask1LetterList = list()\n",
    "\n",
    "    for row in range(gridHeight):  #  Number of rows in a masked input grid\n",
    "        for col in range(gridWidth):  # number of columns in a masked input grid\n",
    "            localGridElement = mask1LetterArray[row,col] \n",
    "            mask1LetterList.append(localGridElement)   \n",
    "\n",
    "    return (mask1LetterList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access Needed Data Files from Grey Box Run\n",
    "\n",
    "The following are a series of functions to access the data files and convert the retrieved data from lists into arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGB1wWeightFile (): \n",
    "\n",
    "    GB1wWeightList = list()\n",
    "    with open(\"GB1wWeightFile\", \"r\") as infile:\n",
    "\n",
    "        reader = csv.reader(infile)\n",
    "        for row in reader:\n",
    "            colnum = 0\n",
    "            theRow = row\n",
    "            for col in row:\n",
    "                data = float(theRow[colnum])\n",
    "            GB1wWeightList.append(data)\n",
    "    \n",
    "    return GB1wWeightList "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGB1vWeightFile (): \n",
    "\n",
    "    GB1vWeightList = list()\n",
    "    with open('GB1vWeightFile', \"r\") as infile:\n",
    "\n",
    "        reader = csv.reader(infile)\n",
    "        for row in reader:\n",
    "            colnum = 0\n",
    "            theRow = row\n",
    "            for col in row:\n",
    "                data = float(theRow[colnum])\n",
    "            GB1vWeightList.append(data)\n",
    "       \n",
    "    return GB1vWeightList     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstructGB1wWeightArray (GB1wWeightList):\n",
    "\n",
    "    numUpperNodes = GB1hiddenArrayLength\n",
    "    numLowerNodes = GB1inputArrayLength \n",
    "    \n",
    "    GB1wWeightArray = np.zeros((numUpperNodes,numLowerNodes))    # initialize the weight matrix with 0's     \n",
    "\n",
    "  \n",
    "    for row in range(numUpperNodes):  #  Number of rows in weightMatrix\n",
    "        # For an input-to-hidden weight matrix, the rows correspond to the number of hidden nodes\n",
    "        #    and the columns correspond to the number of input nodes.\n",
    "        #    This creates an HxI matrix, which can be multiplied by the input matrix (expressed as a column)\n",
    "        # Similarly, for a hidden-to-output matrix, the rows correspond to the number of output nodes.\n",
    "        for col in range(numLowerNodes):  # number of columns in matrix 2\n",
    "            localPosition = row*numLowerNodes + col            \n",
    "            localWeight = GB1wWeightList[localPosition]\n",
    "            GB1wWeightArray[row,col] = localWeight\n",
    "    print (' ')\n",
    "    print (' In reconstructWeightArray')\n",
    "    print()\n",
    "    print('Length of GB1wWeightArray is: ', len(GB1wWeightArray))\n",
    "\n",
    "                                                     \n",
    "    return GB1wWeightArray  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstructGB1vWeightArray (GB1vWeightList):\n",
    "\n",
    "    numUpperNodes = GB1outputArrayLength\n",
    "    numLowerNodes = GB1hiddenArrayLength \n",
    "    \n",
    "    GB1vWeightArray = np.zeros((numUpperNodes,numLowerNodes))    # iniitalize the weight matrix with 0's     \n",
    "  \n",
    "    for row in range(numUpperNodes):  #  Number of rows in weightMatrix\n",
    "        # For a hidden-to-output weight matrix, the rows correspond to the number of output nodes\n",
    "        #    and the columns correspond to the number of hidden nodes.\n",
    "        #    This creates an OxH matrix, which can be multiplied by the hidden nodes matrix (expressed as a column)\n",
    "\n",
    "        for col in range(numLowerNodes):  # number of columns in matrix 2\n",
    "            localPosition = row*numLowerNodes + col\n",
    "            localWeight = GB1vWeightList[localPosition]\n",
    "            GB1vWeightArray[row,col] = localWeight\n",
    "\n",
    "                                                     \n",
    "    return GB1vWeightArray "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGB1wBiasWeightFile (): \n",
    "\n",
    "    GB1wBiasWeightList = list()\n",
    "    with open('GB1wBiasWeightFile', \"r\") as infile:\n",
    "\n",
    "        reader = csv.reader(infile)\n",
    "        for row in reader:\n",
    "            colnum = 0\n",
    "            theRow = row\n",
    "            for col in row:\n",
    "                data = float(theRow[colnum])\n",
    "            GB1wBiasWeightList.append(data)\n",
    "    print (' ')\n",
    "    print (' Reading the GB1wBiasWeight bias weights back from the file:')\n",
    "    print()\n",
    "    print('Length of GB1wBiasWeightList is: ', len(GB1wBiasWeightList))\n",
    "    return GB1wBiasWeightList                                                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGB1vBiasWeightFile (): \n",
    "\n",
    "    GB1vBiasWeightList = list()\n",
    "    with open('GB1vBiasWeightFile', \"r\") as infile:\n",
    "\n",
    "        reader = csv.reader(infile)\n",
    "        for row in reader:\n",
    "            colnum = 0\n",
    "            theRow = row\n",
    "            for col in row:\n",
    "                data = float(theRow[colnum])\n",
    "            GB1vBiasWeightList.append(data)\n",
    "       \n",
    "    return GB1vBiasWeightList  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstructGB1wBiasWeightArray (GB1wBiasWeightList):\n",
    "\n",
    "    GB1wBiasWeightArray = np.zeros(GB1hiddenArrayLength)    # initialize the weight matrix with 0's     \n",
    "\n",
    "    print(' ')\n",
    "    print (' in reconstructGB1wWeightArray')  \n",
    "    for node in range(GB1hiddenArrayLength):  #  Number of hidden bias nodes          \n",
    "            localWeight = GB1wBiasWeightList[node]\n",
    "            GB1wBiasWeightArray[node] = localWeight\n",
    "    print (' ')\n",
    "    print (' In reconstructGB1wBiasWeightArray') \n",
    "    print()\n",
    "    print('The length of GB1wBiasWeightArray is:  ',len(GB1wBiasWeightArray))\n",
    "    print()\n",
    "    print (' The recovered hidden bias weight matrix is: ')\n",
    "    print()\n",
    "    print (GB1wBiasWeightArray)\n",
    "                                                     \n",
    "    return GB1wBiasWeightArray "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstructGB1vBiasWeightArray (GB1vBiasWeightList):\n",
    "    \n",
    "    GB1vBiasWeightArray = np.zeros(GB1outputArrayLength)    # iniitalize the weight matrix with 0's     \n",
    "  \n",
    "    for node in range(GB1outputArrayLength):  #  Number of output bias nodes\n",
    "            localWeight = GB1vBiasWeightList[node]\n",
    "            GB1vBiasWeightArray[node] = localWeight\n",
    "\n",
    "                                                     \n",
    "    return GB1vBiasWeightArray  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4P9IgcNAEjzP"
   },
   "source": [
    "### The 'Main' Procedure-- split out into separate code snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TcxHx5HZd4Mt"
   },
   "outputs": [],
   "source": [
    "# Define the global variables        \n",
    "global inputArrayLength\n",
    "global hiddenArrayLength\n",
    "global outputArrayLength\n",
    "global GB1inputArrayLength\n",
    "global GB1hiddenArrayLength\n",
    "global GB1outputArrayLength    \n",
    "global gridWidth\n",
    "global gridHeight\n",
    "global eGH # expandedGridHeight, defined in function expandLetterBoundaries \n",
    "global eGW # expandedGridWidth defined in function expandLetterBoundaries \n",
    "global mask1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "colab_type": "code",
    "id": "fdqdOIvLiLlz",
    "outputId": "9c6769c0-7858-423a-945f-3fd225920929"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  The number of nodes at each level are:\n",
      "    Input: 9x9 (square array)\n",
      "    Hidden:  6\n",
      "    Output:  9\n",
      "\n",
      " inputArrayLength =  90\n",
      " hiddenArrayLength =  6\n",
      " outputArrayLength =  9\n",
      " gridSize =  9\n"
     ]
    }
   ],
   "source": [
    "arraySizeList = list() # empty list\n",
    "\n",
    "# Obtain the actual sizes for each layer of the network       \n",
    "arraySizeList = obtainNeuralNetworkSizeSpecs ()\n",
    "    \n",
    "# Unpack the list; ascribe the various elements of the list to the sizes of different network layers\n",
    "# Note: A word on Python encoding ... the actually length of the array, in each of these three cases, \n",
    "#       will be xArrayLength. For example, the inputArrayLength for the 9x9 pixel array is 81. \n",
    "#       These values are passed to various procedures. They start filling in actual array values,\n",
    "#       where the array values start their count at element 0. However, when filling them in using a\n",
    "#       \"for node in range[limit]\" statement, the \"for\" loop fills from 0 up to limit-1. Thus, the\n",
    "#       original xArrayLength size is preserved.   \n",
    "GB1inputArrayLength = arraySizeList [0] \n",
    "GB1hiddenArrayLength = arraySizeList [1] \n",
    "GB1outputArrayLength = arraySizeList [2] \n",
    "inputArrayLength = arraySizeList [3] \n",
    "hiddenArrayLength = arraySizeList [4] \n",
    "outputArrayLength = arraySizeList [5] \n",
    "    \n",
    "print()\n",
    "print(\" inputArrayLength = \", inputArrayLength)\n",
    "print(\" hiddenArrayLength = \", hiddenArrayLength)\n",
    "print(\" outputArrayLength = \", outputArrayLength)  \n",
    "\n",
    "# Trust that the 2-D array size is the square root oft he inputArrayLength\n",
    "gridSizeFloat = (inputArrayLength+1)**(1/2.0) # convert back to the total number of nodes\n",
    "gridSize = int(gridSizeFloat+0.1) # add a smidge before converting to integer\n",
    "\n",
    "print (' gridSize = ', gridSize)\n",
    "\n",
    "gridWidth = gridSize\n",
    "gridHeight = gridSize\n",
    "expandedGridHeight = gridHeight+2\n",
    "expandedGridWidth = gridWidth+2 \n",
    "eGH = expandedGridHeight\n",
    "eGW = expandedGridWidth       \n",
    "\n",
    "mask1 = (0,1,0,0,1,0,0,1,0) \n",
    "\n",
    "# Parameter definitions for backpropagation, to be replaced with user inputs\n",
    "alpha = 1.0\n",
    "eta = 1  \n",
    "maxNumIterations = 10    # temporarily set to 10 for testing\n",
    "epsilon = 0.01\n",
    "iteration = 0\n",
    "SSE = 0.0\n",
    "numTrainingDataSets = 16\n",
    "allHiddenActivations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " In reconstructWeightArray\n",
      "\n",
      "Length of GB1wWeightArray is:  6\n",
      " \n",
      " Reading the GB1wBiasWeight bias weights back from the file:\n",
      "\n",
      "Length of GB1wBiasWeightList is:  6\n",
      " \n",
      " in reconstructGB1wWeightArray\n",
      " \n",
      " In reconstructGB1wBiasWeightArray\n",
      "\n",
      "The length of GB1wBiasWeightArray is:   6\n",
      "\n",
      " The recovered hidden bias weight matrix is: \n",
      "\n",
      "[ 0.147 -0.404  0.807 -0.785  0.46   0.187]\n"
     ]
    }
   ],
   "source": [
    "# Grey Box 1: \n",
    "\n",
    "#   Read in the weight arrays for two sets of weights; w: input-to-hidden, and v: hidden-to-output\n",
    "\n",
    "# Read the GB1wWeights from stored data back into this program, into a list; return the list\n",
    "GB1wWeightList = readGB1wWeightFile()\n",
    "    \n",
    "# Convert the GB1wWeight list back into a 2-D weight array\n",
    "GB1wWeightArray = reconstructGB1wWeightArray(GB1wWeightList) \n",
    "    \n",
    "# Read the GB1vWeights from stored data back into this program, into a list; return the list\n",
    "GB1vWeightList = readGB1vWeightFile()\n",
    "    \n",
    "# Convert the GB1vWeight list back into a 2-D weight array\n",
    "GB1vWeightArray = reconstructGB1vWeightArray (GB1vWeightList) \n",
    "\n",
    "# Obtain the bias weights from stored data\n",
    "\n",
    "# The GB1wBiasWeightArray is for hidden node biases in Grey Box 1\n",
    "# The GB1vBiasWeightArray is for output node biases in Grey Box 1\n",
    "\n",
    "# Read the GB1wBiasWeights from stored data back into this program, into a list; return the list\n",
    "GB1wBiasWeightList = readGB1wBiasWeightFile()\n",
    "    \n",
    "# Convert the GB1wBiasWeight list back into a 2-D weight array\n",
    "GB1wBiasWeightArray = reconstructGB1wBiasWeightArray (GB1wBiasWeightList) \n",
    "    \n",
    "# Read the GB1vBiasWeights from stored data back into this program, into a list; return the list\n",
    "GB1vBiasWeightList = readGB1vBiasWeightFile()\n",
    "    \n",
    "# Convert the GB1vBiasWeight list back into a 2-D weight array\n",
    "GB1vBiasWeightArray = reconstructGB1vBiasWeightArray (GB1vBiasWeightList) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "thk64IqjlMXV"
   },
   "outputs": [],
   "source": [
    "# Initialize the weight arrays for two sets of weights; w: input-to-hidden, and v: hidden-to-output\n",
    "####################################################################################################                \n",
    "seed(79)\n",
    "\n",
    "#\n",
    "# The wWeightArray is for Input-to-Hidden\n",
    "# The vWeightArray is for Hidden-to-Output\n",
    "\n",
    "wWeightArraySizeList = (inputArrayLength, hiddenArrayLength)\n",
    "vWeightArraySizeList = (hiddenArrayLength, outputArrayLength)\n",
    "biasHiddenWeightArraySize = hiddenArrayLength\n",
    "biasOutputWeightArraySize = outputArrayLength        \n",
    "\n",
    "# The node-to-node connection weights are stored in a 2-D array\n",
    "\n",
    "wWeightArray = initializeWeightArray (wWeightArraySizeList)\n",
    "  \n",
    "vWeightArray = initializeWeightArray (vWeightArraySizeList)\n",
    "\n",
    "# The bias weights are stored in a 1-D array         \n",
    "biasHiddenWeightArray = initializeBiasWeightArray (biasHiddenWeightArraySize)\n",
    "biasOutputWeightArray = initializeBiasWeightArray (biasOutputWeightArraySize) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4-Jv12Aalrfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "  Before training:\n",
      " \n",
      "  Data Set Number 1  for letter  A  with letter number  2\n",
      " \n",
      " The hidden node activations are:\n",
      "[0.05  0.844 0.501 0.56  0.906 0.121]\n",
      " \n",
      " The output node activations are:\n",
      "[0.765 0.465 0.63  0.654 0.415 0.448 0.508 0.341 0.369]\n",
      "\n",
      "Desired Class Number is:   0\n",
      "\n",
      " \n",
      " The desired output array values are: \n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " \n",
      " The error values are:\n",
      "[ 0.235 -0.465 -0.63  -0.654 -0.415 -0.448 -0.508 -0.341 -0.369]\n",
      "New SSE = 1.979395\n",
      " \n",
      "  Data Set Number 2  for letter  B  with letter number  3\n",
      " \n",
      " The hidden node activations are:\n",
      "[0.975 0.975 0.402 0.775 0.987 0.109]\n",
      " \n",
      " The output node activations are:\n",
      "[0.769 0.538 0.7   0.741 0.58  0.324 0.463 0.224 0.318]\n",
      "\n",
      "Desired Class Number is:   1\n",
      "\n",
      " \n",
      " The desired output array values are: \n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " \n",
      " The error values are:\n",
      "[-0.769  0.462 -0.7   -0.741 -0.58  -0.324 -0.463 -0.224 -0.318]\n",
      "New SSE = 2.651089\n",
      " \n",
      "  Data Set Number 3  for letter  C  with letter number  4\n",
      " \n",
      " The hidden node activations are:\n",
      "[0.981 0.704 0.717 0.704 0.983 0.883]\n",
      " \n",
      " The output node activations are:\n",
      "[0.858 0.495 0.481 0.651 0.715 0.401 0.632 0.285 0.177]\n",
      "\n",
      "Desired Class Number is:   2\n",
      "\n",
      " \n",
      " The desired output array values are: \n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " \n",
      " The error values are:\n",
      "[-0.858 -0.495  0.519 -0.651 -0.715 -0.401 -0.632 -0.285 -0.177]\n",
      "New SSE = 2.859020\n",
      " \n",
      "  Data Set Number 4  for letter  D  with letter number  5\n",
      " \n",
      " The hidden node activations are:\n",
      "[0.957 0.895 0.658 0.785 0.984 0.688]\n",
      " \n",
      " The output node activations are:\n",
      "[0.826 0.517 0.578 0.683 0.658 0.364 0.599 0.279 0.203]\n",
      "\n",
      "Desired Class Number is:   3\n",
      "\n",
      " \n",
      " The desired output array values are: \n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " \n",
      " The error values are:\n",
      "[-0.826 -0.517 -0.578  0.317 -0.658 -0.364 -0.599 -0.279 -0.203]\n",
      "New SSE = 2.428288\n",
      " \n",
      "  Data Set Number 5  for letter  E  with letter number  6\n",
      " \n",
      " The hidden node activations are:\n",
      "[0.95  0.327 0.743 0.393 0.99  0.738]\n",
      " \n",
      " The output node activations are:\n",
      "[0.891 0.435 0.341 0.608 0.737 0.469 0.62  0.217 0.207]\n",
      "\n",
      "Desired Class Number is:   4\n",
      "\n",
      " \n",
      " The desired output array values are: \n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " \n",
      " The error values are:\n",
      "[-0.891 -0.435 -0.341 -0.608  0.263 -0.469 -0.62  -0.217 -0.207]\n",
      "New SSE = 2.232563\n",
      " \n",
      "  Data Set Number 6  for letter  F  with letter number  7\n",
      " \n",
      " The hidden node activations are:\n",
      "[0.925 0.139 0.945 0.065 0.992 0.372]\n",
      " \n",
      " The output node activations are:\n",
      "[0.915 0.36  0.254 0.584 0.672 0.493 0.633 0.114 0.258]\n",
      "\n",
      "Desired Class Number is:   4\n",
      "\n",
      " \n",
      " The desired output array values are: \n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " \n",
      " The error values are:\n",
      "[-0.915 -0.36  -0.254 -0.584  0.328 -0.493 -0.633 -0.114 -0.258]\n",
      "New SSE = 2.202141\n",
      " \n",
      "  Data Set Number 7  for letter  G  with letter number  8\n",
      " \n",
      " The hidden node activations are:\n",
      "[0.976 0.952 0.73  0.597 0.992 0.843]\n",
      " \n",
      " The output node activations are:\n",
      "[0.83  0.541 0.514 0.621 0.698 0.4   0.662 0.254 0.166]\n",
      "\n",
      "Desired Class Number is:   1\n",
      "\n",
      " \n",
      " The desired output array values are: \n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " \n",
      " The error values are:\n",
      "[-0.83   0.459 -0.514 -0.621 -0.698 -0.4   -0.662 -0.254 -0.166]\n",
      "New SSE = 2.726784\n",
      " \n",
      "  Data Set Number 8  for letter  H  with letter number  9\n",
      " \n",
      " The hidden node activations are:\n",
      "[0.193 0.358 0.957 0.461 0.984 0.077]\n",
      " \n",
      " The output node activations are:\n",
      "[0.887 0.31  0.421 0.655 0.38  0.461 0.563 0.216 0.388]\n",
      "\n",
      "Desired Class Number is:   0\n",
      "\n",
      " \n",
      " The desired output array values are: \n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " \n",
      " The error values are:\n",
      "[ 0.113 -0.31  -0.421 -0.655 -0.38  -0.461 -0.563 -0.216 -0.388]\n",
      "New SSE = 1.585664\n",
      " \n",
      "  Data Set Number 9  for letter  I  with letter number  10\n",
      " \n",
      " The hidden node activations are:\n",
      "[0.918 0.866 0.146 0.966 0.796 0.192]\n",
      " \n",
      " The output node activations are:\n",
      "[0.726 0.555 0.761 0.791 0.636 0.297 0.405 0.322 0.306]\n",
      "\n",
      "Desired Class Number is:   5\n",
      "\n",
      " \n",
      " The desired output array values are: \n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " \n",
      " The error values are:\n",
      "[-0.726 -0.555 -0.761 -0.791 -0.636  0.703 -0.405 -0.322 -0.306]\n",
      "New SSE = 3.299711\n",
      " \n",
      "  Data Set Number 10  for letter  J  with letter number  11\n",
      " \n",
      " The hidden node activations are:\n",
      "[0.274 0.92  0.159 0.988 0.918 0.592]\n",
      " \n",
      " The output node activations are:\n",
      "[0.721 0.562 0.723 0.699 0.587 0.415 0.454 0.563 0.294]\n",
      "\n",
      "Desired Class Number is:   5\n",
      "\n",
      " \n",
      " The desired output array values are: \n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " \n",
      " The error values are:\n",
      "[-0.721 -0.562 -0.723 -0.699 -0.587  0.585 -0.454 -0.563 -0.294]\n",
      "New SSE = 3.142242\n",
      " \n",
      "  Data Set Number 11  for letter  K  with letter number  12\n",
      " \n",
      " The hidden node activations are:\n",
      "[0.964 0.384 0.976 0.979 0.98  0.023]\n",
      " \n",
      " The output node activations are:\n",
      "[0.902 0.306 0.548 0.804 0.444 0.286 0.5   0.166 0.363]\n",
      "\n",
      "Desired Class Number is:   6\n",
      "\n",
      " \n",
      " The desired output array values are: \n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " \n",
      " The error values are:\n",
      "[-0.902 -0.306 -0.548 -0.804 -0.444 -0.286  0.5   -0.166 -0.363]\n",
      "New SSE = 2.543504\n",
      " \n",
      "  Data Set Number 12  for letter  L  with letter number  13\n",
      " \n",
      " The hidden node activations are:\n",
      "[0.937 0.826 0.95  0.965 0.942 0.557]\n",
      " \n",
      " The output node activations are:\n",
      "[0.864 0.421 0.583 0.744 0.541 0.305 0.62  0.238 0.22 ]\n",
      "\n",
      "Desired Class Number is:   7\n",
      "\n",
      " \n",
      " The desired output array values are: \n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " \n",
      " The error values are:\n",
      "[-0.864 -0.421 -0.583 -0.744 -0.541 -0.305 -0.62   0.762 -0.22 ]\n",
      "New SSE = 3.215726\n",
      " \n",
      "  Data Set Number 13  for letter  M  with letter number  14\n",
      " \n",
      " The hidden node activations are:\n",
      "[0.511 0.3   0.912 0.743 0.946 0.194]\n",
      " \n",
      " The output node activations are:\n",
      "[0.895 0.312 0.468 0.729 0.449 0.387 0.535 0.233 0.352]\n",
      "\n",
      "Desired Class Number is:   8\n",
      "\n",
      " \n",
      " The desired output array values are: \n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " \n",
      " The error values are:\n",
      "[-0.895 -0.312 -0.468 -0.729 -0.449 -0.387 -0.535 -0.233  0.648]\n",
      "New SSE = 2.760300\n",
      " \n",
      "  Data Set Number 14  for letter  N  with letter number  15\n",
      " \n",
      " The hidden node activations are:\n",
      "[0.672 0.696 0.655 0.856 0.983 0.053]\n",
      " \n",
      " The output node activations are:\n",
      "[0.834 0.413 0.635 0.755 0.457 0.338 0.475 0.242 0.368]\n",
      "\n",
      "Desired Class Number is:   8\n",
      "\n",
      " \n",
      " The desired output array values are: \n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " \n",
      " The error values are:\n",
      "[-0.834 -0.413 -0.635 -0.755 -0.457 -0.338 -0.475 -0.242  0.632]\n",
      "New SSE = 2.846469\n",
      " \n",
      "  Data Set Number 15  for letter  O  with letter number  16\n",
      " \n",
      " The hidden node activations are:\n",
      "[0.862 0.851 0.495 0.237 0.987 0.949]\n",
      " \n",
      " The output node activations are:\n",
      "[0.806 0.6   0.43  0.514 0.787 0.509 0.661 0.273 0.156]\n",
      "\n",
      "Desired Class Number is:   3\n",
      "\n",
      " \n",
      " The desired output array values are: \n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " \n",
      " The error values are:\n",
      "[-0.806 -0.6   -0.43   0.486 -0.787 -0.509 -0.661 -0.273 -0.156]\n",
      "New SSE = 2.844962\n",
      " \n",
      "  Data Set Number 16  for letter  P  with letter number  17\n",
      " \n",
      " The hidden node activations are:\n",
      "[0.909 0.152 0.895 0.186 0.985 0.169]\n",
      " \n",
      " The output node activations are:\n",
      "[0.909 0.347 0.309 0.637 0.617 0.455 0.58  0.113 0.308]\n",
      "\n",
      "Desired Class Number is:   1\n",
      "\n",
      " \n",
      " The desired output array values are: \n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " \n",
      " The error values are:\n",
      "[-0.909  0.653 -0.309 -0.637 -0.617 -0.455 -0.58  -0.113 -0.308]\n",
      "New SSE = 2.784745\n"
     ]
    }
   ],
   "source": [
    "# Before we start training, get a baseline set of outputs, errors, and SSE \n",
    "####################################################################################################                \n",
    "                            \n",
    "print (' ')\n",
    "print ('  Before training:')\n",
    "   \n",
    "ComputeOutputsAcrossAllTrainingData (alpha, numTrainingDataSets, wWeightArray, biasHiddenWeightArray, \n",
    "    vWeightArray, biasOutputWeightArray, GB1wWeightArray, GB1wBiasWeightArray, GB1vWeightArray, GB1vBiasWeightArray)                           \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "_gsGSPyXpafY",
    "outputId": "3645bf90-272f-47fb-c46c-915ba95adc97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of while loop at iteration  10\n"
     ]
    }
   ],
   "source": [
    "# Perform backpropagation during each iteration\n",
    "# This code pulled from 'Main' and modified to return the new weights for use\n",
    "# outside of the loop\n",
    "\n",
    "vWeightArrayPost = np.array([])\n",
    "wWeightArrayPost = np.array([])\n",
    "biasHiddenWeightsPost = np.array([])\n",
    "biasOutputWeightsPost = np.array([])\n",
    "\n",
    "while iteration < maxNumIterations: \n",
    "    \n",
    "    # Increment the iteration count\n",
    "    iteration = iteration +1\n",
    "    \n",
    "    vWeightArrayPost = np.array([]) # Re-initializing the new weight arrays \n",
    "    wWeightArrayPost = np.array([]) # so they only contain the final weights\n",
    "    biasHiddenWeightsPost = np.array([])\n",
    "    biasOutputWeightsPost = np.array([])\n",
    "                          \n",
    "    # Re-initialize the training list at the start of each iteration\n",
    "    trainingDataList = (0,[0,0,0,0,0,0,0,0\n",
    "                        , 0,0,0,0,0,0,0,0,0, 0,0,0,0,0,0,0,0,0, 0,0,0,0,0,0,0,0,0\n",
    "                        , 0,0,0,0,0,0,0,0,0, 0,0,0,0,0,0,0,0,0, 0,0,0,0,0,0,0,0,0\n",
    "                        , 0,0,0,0,0,0,0,0,0, 0,0,0,0,0,0,0,0,0],0,' ', 0, ' ')\n",
    "    # Populate the training list with a random data set\n",
    "    dataSet = random.randint(1, numTrainingDataSets)\n",
    "    trainingDataList = obtainSelectedAlphabetTrainingValues(dataSet)\n",
    "    \n",
    "    # Create an input array based on the input training data list\n",
    "    GB1inputDataList = []\n",
    "    GB1inputDataArray = np.zeros(GB1inputArrayLength)\n",
    "    \n",
    "    # Use the items in index 1 as the training inputs\n",
    "    thisTrainingDataList = list()\n",
    "    thisTrainingDataList = trainingDataList[1]\n",
    "    \n",
    "    for node in range(GB1inputArrayLength):\n",
    "        trainingData = thisTrainingDataList[node]\n",
    "        GB1inputDataList.append(trainingData)\n",
    "      #inputDataArray[node] = trainingData\n",
    "      \n",
    "    # Create desired output array, from 4th element\n",
    "    GB1desiredOutputArray = np.zeros(GB1outputArrayLength)\n",
    "    GB1desiredClass = trainingDataList[4]\n",
    "    GB1desiredOutputArray[GB1desiredClass] = 1\n",
    "    \n",
    "    GB1hiddenArray = ComputeGB1SingleFeedforwardPassFirstStep (alpha, GB1inputDataArray, GB1wWeightArray, GB1wBiasWeightArray)\n",
    "\n",
    "    GB1outputArray = ComputeGB1SingleFeedforwardPassSecondStep (alpha, GB1hiddenArray,GB1vWeightArray, GB1vBiasWeightArray)\n",
    "\n",
    "    # STEP 2: Create a masked version of the original input\n",
    "\n",
    "    expandedLetterArray = list()\n",
    "    expandedLetterArray = expandLetterBoundaries (trainingDataList)\n",
    "\n",
    "\n",
    "    \n",
    "    mask1LetterArray = mask1LetterFunc(expandedLetterArray)\n",
    "    mask1LetterList = convertArrayToList(mask1LetterArray)\n",
    "    \n",
    "    # Step 3: Create the new input array, combining results from GB1 together with the masking filter result(s)\n",
    "\n",
    "    inputDataList = [] \n",
    "    inputDataArray = np.zeros(inputArrayLength) \n",
    "\n",
    "\n",
    "# Note: This duplicates some steps done earlier, creating the inputs for GB1\n",
    "# Fill the first part of the training data list with the usual inputs\n",
    "\n",
    "    inputDataList = []      \n",
    "    inputDataArray =  np.zeros(inputArrayLength)\n",
    "        \n",
    "    thisTrainingDataList = list()                                                                            \n",
    "    thisTrainingDataList = trainingDataList[1]    # the 81 input array    \n",
    "    for node in range(GB1inputArrayLength):         # this should be length 81\n",
    "        trainingData = thisTrainingDataList[node]  \n",
    "        inputDataList.append(trainingData)\n",
    "\n",
    "# Fill the second part of the training data list with the outputs from GB1          \n",
    "    for node in range(GB1outputArrayLength):  # this should be equal to the number of classes used\n",
    "        trainingData = GB1outputArray[node]  # this should be the weights saved at the output level from GB1\n",
    "        inputDataList.append(trainingData)    # appending GB1 output weights to the list of original inputs directly above        \n",
    "\n",
    "# Create an input array with both the original training data and the outputs from GB1\n",
    "    for node in range(inputArrayLength):  # defined as number of original inputs plus number of outputs from GB1\n",
    "        inputDataArray[node] = inputDataList[node]  \n",
    "        \n",
    "# Step 4: Create the new desired output array, using the full number of classes in the input data\n",
    "\n",
    "    desiredOutputArray = np.zeros(outputArrayLength)    # iniitalize the output array with 0's\n",
    "    desiredClass = trainingDataList[4]                 # identify the desired class number\n",
    "    desiredOutputArray[desiredClass] = 1  \n",
    "    \n",
    "# Step 5: Do backpropagation training using the combined (GB1 + MF) inputs and full set of desired outputs\n",
    "    \n",
    "    \n",
    "    # Compute feedforward pass\n",
    "    hiddenArray = ComputeSingleFeedforwardPassFirstStep (alpha, inputDataArray\n",
    "                                                         , wWeightArray\n",
    "                                                         , biasHiddenWeightArray)\n",
    "    outputArray = ComputeSingleFeedforwardPassSecondStep (alpha, hiddenArray\n",
    "                                                          ,vWeightArray\n",
    "                                                          , biasOutputWeightArray)\n",
    "    # Initialize the rror array\n",
    "    errorArray = np.zeros(outputArrayLength)\n",
    "    \n",
    "    # Determine the error and fill the array plus calculate new SSE\n",
    "    newSSE = 0.0\n",
    "    for node in range(outputArrayLength):\n",
    "      errorArray[node] = desiredOutputArray[node] - outputArray[node]\n",
    "      newSSE += errorArray[node]*errorArray[node]\n",
    "      \n",
    "    # Backpropagation\n",
    "    \n",
    "    # Ouput to Hidden backprop\n",
    "    newVWeightArray = backpropagateOutputToHidden (alpha, eta, arraySizeList\n",
    "                                                   , errorArray, outputArray\n",
    "                                                   , hiddenArray, vWeightArray)\n",
    "    \n",
    "    \n",
    "    newBiasOutputWeightArray = backpropagateBiasOutputWeights (alpha, eta\n",
    "                                                               , arraySizeList\n",
    "                                                               , errorArray\n",
    "                                                               , outputArray\n",
    "                                                               , biasOutputWeightArray) \n",
    "    # Hidden to Input backprop\n",
    "    newWWeightArray = backpropagateHiddenToInput (alpha, eta, arraySizeList\n",
    "                                                  , errorArray, outputArray\n",
    "                                                  , hiddenArray, inputDataList\n",
    "                                                  , vWeightArray, wWeightArray\n",
    "                                                  , biasHiddenWeightArray\n",
    "                                                  , biasOutputWeightArray)\n",
    "    newBiasHiddenWeightArray = backpropagateBiasHiddenWeights (alpha, eta\n",
    "                                                               , arraySizeList\n",
    "                                                               , errorArray\n",
    "                                                               , outputArray\n",
    "                                                               , hiddenArray\n",
    "                                                               , inputDataList\n",
    "                                                               , vWeightArray\n",
    "                                                               , wWeightArray\n",
    "                                                               , biasHiddenWeightArray\n",
    "                                                               , biasOutputWeightArray)\n",
    "    \n",
    "    # Update the weight and bias matrices\n",
    "    # Hidden-to-output update\n",
    "    vWeightArray = newVWeightArray[:]\n",
    "    \n",
    "    \n",
    "    biasOutputWeightArray = newBiasOutputWeightArray[:]\n",
    "    \n",
    "    # Input-to-hidden update\n",
    "    wWeightArray = newWWeightArray[:]  \n",
    "    \n",
    "    biasHiddenWeightArray = newBiasHiddenWeightArray[:] \n",
    "    \n",
    "    # Perform a forward pass with the new weights\n",
    "    hiddenArray = ComputeSingleFeedforwardPassFirstStep (alpha, inputDataList\n",
    "                                                         , wWeightArray\n",
    "                                                         , biasHiddenWeightArray)\n",
    "    outputArray = ComputeSingleFeedforwardPassSecondStep (alpha, hiddenArray\n",
    "                                                          , vWeightArray\n",
    "                                                          , biasOutputWeightArray)\n",
    "    \n",
    "    \n",
    "    # Check the new SSE\n",
    "    newSSE = 0.0\n",
    "    for node in range(outputArrayLength):\n",
    "      errorArray[node] - desiredOutputArray[node] - outputArray[node]\n",
    "      newSSE += errorArray[node]*errorArray[node]\n",
    "      \n",
    "    if newSSE < epsilon:\n",
    "      break\n",
    "# Append to our w weight array\n",
    "vWeightArrayPost = vWeightArray\n",
    "wWeightArrayPost = wWeightArray\n",
    "biasOutputWeightsPost = biasOutputWeightArray\n",
    "biasHiddenWeightsPost = biasHiddenWeightArray\n",
    "print(\"Out of while loop at iteration \", iteration)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "  \n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "TAcz4fLNnCuz",
    "outputId": "62e9d5c4-cef0-4293-e08f-2266b6a54b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  After training:\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"  After training:\")  \n",
    "\n",
    "# This is the code from ComputeOutputsAcrossAllTrainingData, modified for\n",
    "# the outputs I am looking for\n",
    "\n",
    "selectedTrainingDataSet = 1 \n",
    "seed(79)\n",
    "                                \n",
    "                              \n",
    "    \n",
    "allHiddenActivationsPostLearn = np.array([])\n",
    "allOutputActivationsPostLearn = np.array([])\n",
    "desiredOutputPost = np.array([])\n",
    "\n",
    "while selectedTrainingDataSet < numTrainingDataSets + 1: \n",
    "    #print()\n",
    "    #print(\" the selected Training Data Set is \", selectedTrainingDataSet)\n",
    "    trainingDataList = obtainSelectedAlphabetTrainingValues (selectedTrainingDataSet)\n",
    "# Note: the trainingDataList is a list comprising several values:\n",
    "#    - the 0th is the list number \n",
    "#    - the 1st is the actual list of the input training values\n",
    "#    - etc. \n",
    "\n",
    "    trainingDataInputList = trainingDataList[1]   \n",
    "    \n",
    "    # Obtain the outputs from GB1\n",
    "            \n",
    "    GB1inputDataList = [] \n",
    "    GB1inputDataArray = np.zeros(GB1inputArrayLength) \n",
    "    for node in range(GB1inputArrayLength): \n",
    "        trainingData = trainingDataInputList[node]  \n",
    "        GB1inputDataList.append(trainingData)\n",
    "        GB1inputDataArray[node] = trainingData\n",
    "\n",
    "\n",
    "    GB1hiddenArray = ComputeGB1SingleFeedforwardPassFirstStep (alpha, GB1inputDataArray, GB1wWeightArray, GB1wBiasWeightArray)\n",
    "    GB1outputArray = ComputeGB1SingleFeedforwardPassSecondStep (alpha, GB1hiddenArray, GB1vWeightArray, GB1vBiasWeightArray)   \n",
    "        \n",
    "    inputDataList = [] \n",
    "    inputDataArray = np.zeros(inputArrayLength) \n",
    "\n",
    "    for node in range(GB1inputArrayLength): \n",
    "        trainingData = trainingDataInputList[node]  \n",
    "        inputDataList.append(trainingData)\n",
    "    \n",
    "    for node in range(GB1outputArrayLength): \n",
    "            trainingData = GB1outputArray[node]  \n",
    "            inputDataList.append(trainingData)\n",
    "    \n",
    "    for node in range(inputArrayLength): \n",
    "            inputDataArray[node] = inputDataList[node]    \n",
    "    \n",
    "\n",
    "    letterNum = trainingDataList[2] +1\n",
    "    letterChar = trainingDataList[3]  \n",
    "    #print()\n",
    "    #print(\"  Data Set Number\", selectedTrainingDataSet, \" for letter \", letterChar, \" with letter number \", letterNum) \n",
    "\n",
    "    hiddenArray = np.array(ComputeSingleFeedforwardPassFirstStep (alpha, inputDataArray, wWeightArrayPost, biasHiddenWeightsPost))\n",
    "    allHiddenActivationsPostLearn = np.append(allHiddenActivationsPostLearn, hiddenArray)\n",
    "    \n",
    "    outputArray = ComputeSingleFeedforwardPassSecondStep (alpha, hiddenArray, vWeightArrayPost, biasOutputWeightsPost)\n",
    "    allOutputActivationsPostLearn = np.append(allOutputActivationsPostLearn, outputArray)\n",
    "    \n",
    "    desiredOutputArray = np.zeros(outputArrayLength)    # iniitalize the output array with 0's\n",
    "    desiredClass = trainingDataList[4]                 # identify the desired class\n",
    "    desiredOutputArray[desiredClass] = 1\n",
    "    desiredOutputPost = np.append(desiredOutputPost, desiredOutputArray)\n",
    "    \n",
    "    \n",
    "    \n",
    "    selectedTrainingDataSet = selectedTrainingDataSet +1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YlCZZjPxF_Zw"
   },
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "whjW1r8em_Ft"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'allHiddenActivationsPreLearn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-903cf7c6134a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m preHidden = pd.DataFrame([allHiddenActivationsPreLearn[0:6]\n\u001b[0m\u001b[0;32m      6\u001b[0m                          \u001b[1;33m,\u001b[0m\u001b[0mallHiddenActivationsPreLearn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                          \u001b[1;33m,\u001b[0m\u001b[0mallHiddenActivationsPreLearn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'allHiddenActivationsPreLearn' is not defined"
     ]
    }
   ],
   "source": [
    "# Create dataframes for pre-training values of all activations\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "preHidden = pd.DataFrame([allHiddenActivationsPreLearn[0:6]\n",
    "                         ,allHiddenActivationsPreLearn[6:12]\n",
    "                         ,allHiddenActivationsPreLearn[12:18]\n",
    "                         ,allHiddenActivationsPreLearn[18:24]\n",
    "                         ,allHiddenActivationsPreLearn[24:30]\n",
    "                         ,allHiddenActivationsPreLearn[30:36]\n",
    "                         ,allHiddenActivationsPreLearn[36:42]\n",
    "                         ,allHiddenActivationsPreLearn[42:48]\n",
    "                         ,allHiddenActivationsPreLearn[48:54]\n",
    "                         ,allHiddenActivationsPreLearn[54:60]\n",
    "                         ,allHiddenActivationsPreLearn[60:66]\n",
    "                         ,allHiddenActivationsPreLearn[66:72]\n",
    "                         ,allHiddenActivationsPreLearn[72:78]\n",
    "                         ,allHiddenActivationsPreLearn[78:84]\n",
    "                         ,allHiddenActivationsPreLearn[84:90]\n",
    "                         ,allHiddenActivationsPreLearn[90:96]]\n",
    "                         , index = [\"A\", \"B\", \"C\", \"D\"\n",
    "                                   ,\"E\", \"F\", \"G\", \"H\"\n",
    "                                   ,\"I\", \"J\", \"K\", \"L\"\n",
    "                                   ,\"M\", \"N\", \"O\", \"P\"]\n",
    "                        , columns = [\"H0\", \"H1\", \"H2\"\n",
    "                                    , \"H3\", \"H4\", \"H5\"])\n",
    "\n",
    "preOutput = pd.DataFrame([allOutputActivationsPreLearn[0:9]\n",
    "                         ,allOutputActivationsPreLearn[9:18]\n",
    "                         ,allOutputActivationsPreLearn[18:27]\n",
    "                         ,allOutputActivationsPreLearn[27:36]\n",
    "                         ,allOutputActivationsPreLearn[36:45]\n",
    "                         ,allOutputActivationsPreLearn[45:54]\n",
    "                         ,allOutputActivationsPreLearn[54:63]\n",
    "                         ,allOutputActivationsPreLearn[63:72]\n",
    "                         ,allOutputActivationsPreLearn[72:81]\n",
    "                         ,allOutputActivationsPreLearn[81:90]\n",
    "                         ,allOutputActivationsPreLearn[90:99]\n",
    "                         ,allOutputActivationsPreLearn[99:108]\n",
    "                         ,allOutputActivationsPreLearn[108:117]\n",
    "                         ,allOutputActivationsPreLearn[117:126]\n",
    "                         ,allOutputActivationsPreLearn[126:135]\n",
    "                         ,allOutputActivationsPreLearn[135:144]]\n",
    "                         , index = [\"A\", \"B\", \"C\", \"D\"\n",
    "                                   ,\"E\", \"F\", \"G\", \"H\"\n",
    "                                   ,\"I\", \"J\", \"K\", \"L\"\n",
    "                                   ,\"M\", \"N\", \"O\", \"P\"]\n",
    "                        , columns = [\"o0\", \"o1\", \"o2\"\n",
    "                                    , \"o3\", \"o4\", \"o5\"\n",
    "                                    , \"o6\", \"o7\", \"o8\"])\n",
    "\n",
    "desired = pd.DataFrame([desiredOutput[0:9]\n",
    "                         ,desiredOutput[9:18]\n",
    "                         ,desiredOutput[18:27]\n",
    "                         ,desiredOutput[27:36]\n",
    "                         ,desiredOutput[36:45]\n",
    "                         ,desiredOutput[45:54]\n",
    "                         ,desiredOutput[54:63]\n",
    "                         ,desiredOutput[63:72]\n",
    "                         ,desiredOutput[72:81]\n",
    "                         ,desiredOutput[81:90]\n",
    "                         ,desiredOutput[90:99]\n",
    "                         ,desiredOutput[99:108]\n",
    "                         ,desiredOutput[108:117]\n",
    "                         ,desiredOutput[117:126]\n",
    "                         ,desiredOutput[126:135]\n",
    "                         ,desiredOutput[135:144]]\n",
    "                         , index = [\"A\", \"B\", \"C\", \"D\"\n",
    "                                   ,\"E\", \"F\", \"G\", \"H\"\n",
    "                                   ,\"I\", \"J\", \"K\", \"L\"\n",
    "                                   ,\"M\", \"N\", \"O\", \"P\"]\n",
    "                        , columns = [\"o0\", \"o1\", \"o2\"\n",
    "                                    , \"o3\", \"o4\", \"o5\"\n",
    "                                    , \"o6\", \"o7\", \"o8\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sIkARr96pbhW"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'desiredOutput' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-129-60729705c74a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m                                     , \"o6\", \"o7\", \"o8\"])\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m postDesired = pd.DataFrame([desiredOutput[0:9]\n\u001b[0m\u001b[0;32m     51\u001b[0m                          \u001b[1;33m,\u001b[0m\u001b[0mdesiredOutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m                          \u001b[1;33m,\u001b[0m\u001b[0mdesiredOutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m27\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'desiredOutput' is not defined"
     ]
    }
   ],
   "source": [
    "# Create data frames for post-output values of all activations\n",
    "\n",
    "postHidden = pd.DataFrame([allHiddenActivationsPostLearn[0:6]\n",
    "                         ,allHiddenActivationsPostLearn[6:12]\n",
    "                         ,allHiddenActivationsPostLearn[12:18]\n",
    "                         ,allHiddenActivationsPostLearn[18:24]\n",
    "                         ,allHiddenActivationsPostLearn[24:30]\n",
    "                         ,allHiddenActivationsPostLearn[30:36]\n",
    "                         ,allHiddenActivationsPostLearn[36:42]\n",
    "                         ,allHiddenActivationsPostLearn[42:48]\n",
    "                         ,allHiddenActivationsPostLearn[48:54]\n",
    "                         ,allHiddenActivationsPostLearn[54:60]\n",
    "                         ,allHiddenActivationsPostLearn[60:66]\n",
    "                         ,allHiddenActivationsPostLearn[66:72]\n",
    "                         ,allHiddenActivationsPostLearn[72:78]\n",
    "                         ,allHiddenActivationsPostLearn[78:84]\n",
    "                         ,allHiddenActivationsPostLearn[84:90]\n",
    "                         ,allHiddenActivationsPostLearn[90:96]]\n",
    "                         , index = [\"A\", \"B\", \"C\", \"D\"\n",
    "                                   ,\"E\", \"F\", \"G\", \"H\"\n",
    "                                   ,\"I\", \"J\", \"K\", \"L\"\n",
    "                                   ,\"M\", \"N\", \"O\", \"P\"]\n",
    "                        , columns = [\"H0\", \"H1\", \"H2\"\n",
    "                                    , \"H3\", \"H4\", \"H5\"])\n",
    "\n",
    "postOutput = pd.DataFrame([allOutputActivationsPostLearn[0:9]\n",
    "                         ,allOutputActivationsPostLearn[9:18]\n",
    "                         ,allOutputActivationsPostLearn[18:27]\n",
    "                         ,allOutputActivationsPostLearn[27:36]\n",
    "                         ,allOutputActivationsPostLearn[36:45]\n",
    "                         ,allOutputActivationsPostLearn[45:54]\n",
    "                         ,allOutputActivationsPostLearn[54:63]\n",
    "                         ,allOutputActivationsPostLearn[63:72]\n",
    "                         ,allOutputActivationsPostLearn[72:81]\n",
    "                         ,allOutputActivationsPostLearn[81:90]\n",
    "                         ,allOutputActivationsPostLearn[90:99]\n",
    "                         ,allOutputActivationsPostLearn[99:108]\n",
    "                         ,allOutputActivationsPostLearn[108:117]\n",
    "                         ,allOutputActivationsPostLearn[117:126]\n",
    "                         ,allOutputActivationsPostLearn[126:135]\n",
    "                         ,allOutputActivationsPostLearn[135:144]]\n",
    "                         , index = [\"A\", \"B\", \"C\", \"D\"\n",
    "                                   ,\"E\", \"F\", \"G\", \"H\"\n",
    "                                   ,\"I\", \"J\", \"K\", \"L\"\n",
    "                                   ,\"M\", \"N\", \"O\", \"P\"]\n",
    "                        , columns = [\"o0\", \"o1\", \"o2\"\n",
    "                                    , \"o3\", \"o4\", \"o5\"\n",
    "                                    , \"o6\", \"o7\", \"o8\"])\n",
    "\n",
    "postDesired = pd.DataFrame([desiredOutput[0:9]\n",
    "                         ,desiredOutput[9:18]\n",
    "                         ,desiredOutput[18:27]\n",
    "                         ,desiredOutput[27:36]\n",
    "                         ,desiredOutput[36:45]\n",
    "                         ,desiredOutput[45:54]\n",
    "                         ,desiredOutput[54:63]\n",
    "                         ,desiredOutput[63:72]\n",
    "                         ,desiredOutput[72:81]\n",
    "                         ,desiredOutput[81:90]\n",
    "                         ,desiredOutput[90:99]\n",
    "                         ,desiredOutput[99:108]\n",
    "                         ,desiredOutput[108:117]\n",
    "                         ,desiredOutput[117:126]\n",
    "                         ,desiredOutput[126:135]\n",
    "                         ,desiredOutput[135:144]]\n",
    "                         , index = [\"A\", \"B\", \"C\", \"D\"\n",
    "                                   ,\"E\", \"F\", \"G\", \"H\"\n",
    "                                   ,\"I\", \"J\", \"K\", \"L\"\n",
    "                                   ,\"M\", \"N\", \"O\", \"P\"]\n",
    "                        , columns = [\"o0\", \"o1\", \"o2\"\n",
    "                                    , \"o3\", \"o4\", \"o5\"\n",
    "                                    , \"o6\", \"o7\", \"o8\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1906
    },
    "colab_type": "code",
    "id": "RHfBPIooGC5p",
    "outputId": "e0146f98-623a-4f4a-edf6-be5c1bc35894"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H0</th>\n",
       "      <th>H1</th>\n",
       "      <th>H2</th>\n",
       "      <th>H3</th>\n",
       "      <th>H4</th>\n",
       "      <th>H5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.727830</td>\n",
       "      <td>-0.093690</td>\n",
       "      <td>0.655824</td>\n",
       "      <td>0.475866</td>\n",
       "      <td>0.248253</td>\n",
       "      <td>-0.866811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.321437</td>\n",
       "      <td>0.107595</td>\n",
       "      <td>0.391856</td>\n",
       "      <td>-0.359392</td>\n",
       "      <td>-0.520064</td>\n",
       "      <td>0.142841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.689415</td>\n",
       "      <td>-0.463203</td>\n",
       "      <td>-0.398532</td>\n",
       "      <td>-0.590082</td>\n",
       "      <td>-0.424747</td>\n",
       "      <td>0.738922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.523500</td>\n",
       "      <td>-0.889057</td>\n",
       "      <td>-0.887992</td>\n",
       "      <td>0.032942</td>\n",
       "      <td>0.556211</td>\n",
       "      <td>-0.907647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.369475</td>\n",
       "      <td>1.086272</td>\n",
       "      <td>-0.189472</td>\n",
       "      <td>-0.229899</td>\n",
       "      <td>0.880091</td>\n",
       "      <td>0.138221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.705245</td>\n",
       "      <td>0.314280</td>\n",
       "      <td>-0.602125</td>\n",
       "      <td>-0.163876</td>\n",
       "      <td>-0.127460</td>\n",
       "      <td>0.318749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.313449</td>\n",
       "      <td>-0.319188</td>\n",
       "      <td>0.393496</td>\n",
       "      <td>-0.150507</td>\n",
       "      <td>0.958900</td>\n",
       "      <td>-0.217146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.636164</td>\n",
       "      <td>0.478594</td>\n",
       "      <td>0.170882</td>\n",
       "      <td>-0.102815</td>\n",
       "      <td>-0.218526</td>\n",
       "      <td>0.711031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.928013</td>\n",
       "      <td>-0.705388</td>\n",
       "      <td>0.120532</td>\n",
       "      <td>-0.311802</td>\n",
       "      <td>0.484095</td>\n",
       "      <td>0.571152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.043885</td>\n",
       "      <td>0.385562</td>\n",
       "      <td>0.520521</td>\n",
       "      <td>-0.551962</td>\n",
       "      <td>0.607191</td>\n",
       "      <td>1.017549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.397304</td>\n",
       "      <td>0.254821</td>\n",
       "      <td>-0.010637</td>\n",
       "      <td>-0.254493</td>\n",
       "      <td>0.669858</td>\n",
       "      <td>-0.765313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.180043</td>\n",
       "      <td>-0.078013</td>\n",
       "      <td>0.505823</td>\n",
       "      <td>0.133150</td>\n",
       "      <td>0.991329</td>\n",
       "      <td>0.696982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.656112</td>\n",
       "      <td>-0.620301</td>\n",
       "      <td>-0.709265</td>\n",
       "      <td>0.746427</td>\n",
       "      <td>0.018501</td>\n",
       "      <td>-0.234816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.259179</td>\n",
       "      <td>-0.013432</td>\n",
       "      <td>-0.451791</td>\n",
       "      <td>-0.974484</td>\n",
       "      <td>0.110646</td>\n",
       "      <td>0.220679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.635378</td>\n",
       "      <td>0.419068</td>\n",
       "      <td>-0.179007</td>\n",
       "      <td>0.123692</td>\n",
       "      <td>-0.226800</td>\n",
       "      <td>-0.107155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.235748</td>\n",
       "      <td>-0.568458</td>\n",
       "      <td>0.952271</td>\n",
       "      <td>0.730605</td>\n",
       "      <td>0.183998</td>\n",
       "      <td>0.633529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.504899</td>\n",
       "      <td>-0.795931</td>\n",
       "      <td>0.751330</td>\n",
       "      <td>0.252495</td>\n",
       "      <td>-0.765721</td>\n",
       "      <td>0.524133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.783042</td>\n",
       "      <td>0.392692</td>\n",
       "      <td>-0.716904</td>\n",
       "      <td>1.010787</td>\n",
       "      <td>-0.731890</td>\n",
       "      <td>-0.350400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.943952</td>\n",
       "      <td>0.562015</td>\n",
       "      <td>0.578610</td>\n",
       "      <td>0.540053</td>\n",
       "      <td>-0.462542</td>\n",
       "      <td>-0.323191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.824633</td>\n",
       "      <td>0.696988</td>\n",
       "      <td>-0.172379</td>\n",
       "      <td>-0.184408</td>\n",
       "      <td>-0.770429</td>\n",
       "      <td>-0.313344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.344167</td>\n",
       "      <td>-0.437932</td>\n",
       "      <td>-0.704223</td>\n",
       "      <td>-0.266585</td>\n",
       "      <td>-0.153177</td>\n",
       "      <td>0.593064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.479980</td>\n",
       "      <td>-0.728525</td>\n",
       "      <td>-0.656501</td>\n",
       "      <td>-0.292995</td>\n",
       "      <td>-0.297009</td>\n",
       "      <td>0.173929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.083691</td>\n",
       "      <td>-0.061719</td>\n",
       "      <td>-0.625580</td>\n",
       "      <td>0.527606</td>\n",
       "      <td>-0.935239</td>\n",
       "      <td>0.023308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.842410</td>\n",
       "      <td>-0.870627</td>\n",
       "      <td>0.822385</td>\n",
       "      <td>-0.364894</td>\n",
       "      <td>-0.462404</td>\n",
       "      <td>0.791827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.877534</td>\n",
       "      <td>0.248454</td>\n",
       "      <td>-0.121570</td>\n",
       "      <td>-0.068822</td>\n",
       "      <td>-0.624394</td>\n",
       "      <td>-0.018862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.821572</td>\n",
       "      <td>-0.210462</td>\n",
       "      <td>-0.951576</td>\n",
       "      <td>0.948031</td>\n",
       "      <td>-0.494482</td>\n",
       "      <td>0.648225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.794477</td>\n",
       "      <td>-0.478061</td>\n",
       "      <td>-0.640292</td>\n",
       "      <td>-0.493687</td>\n",
       "      <td>0.231146</td>\n",
       "      <td>-0.966012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.654781</td>\n",
       "      <td>0.058267</td>\n",
       "      <td>-0.005305</td>\n",
       "      <td>-0.607076</td>\n",
       "      <td>0.176765</td>\n",
       "      <td>0.595535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.457523</td>\n",
       "      <td>-0.072305</td>\n",
       "      <td>0.613825</td>\n",
       "      <td>0.692523</td>\n",
       "      <td>-0.680311</td>\n",
       "      <td>-0.061927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.561883</td>\n",
       "      <td>0.721890</td>\n",
       "      <td>0.463784</td>\n",
       "      <td>0.250419</td>\n",
       "      <td>-0.733999</td>\n",
       "      <td>-0.744628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-0.428041</td>\n",
       "      <td>0.366194</td>\n",
       "      <td>-0.717949</td>\n",
       "      <td>-0.597317</td>\n",
       "      <td>-0.741615</td>\n",
       "      <td>-0.184528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.212251</td>\n",
       "      <td>-0.014340</td>\n",
       "      <td>-0.707085</td>\n",
       "      <td>0.659017</td>\n",
       "      <td>0.315312</td>\n",
       "      <td>0.721877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.138740</td>\n",
       "      <td>-0.592313</td>\n",
       "      <td>-0.089485</td>\n",
       "      <td>-0.655792</td>\n",
       "      <td>0.862211</td>\n",
       "      <td>-0.778296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.565427</td>\n",
       "      <td>-0.557896</td>\n",
       "      <td>0.843607</td>\n",
       "      <td>0.360004</td>\n",
       "      <td>0.434357</td>\n",
       "      <td>0.896779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.264830</td>\n",
       "      <td>0.055051</td>\n",
       "      <td>0.577843</td>\n",
       "      <td>-0.157622</td>\n",
       "      <td>-0.638294</td>\n",
       "      <td>-0.959093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.520603</td>\n",
       "      <td>0.274520</td>\n",
       "      <td>-0.333823</td>\n",
       "      <td>0.743839</td>\n",
       "      <td>0.213099</td>\n",
       "      <td>-0.088835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>-0.479485</td>\n",
       "      <td>-0.057888</td>\n",
       "      <td>-0.855119</td>\n",
       "      <td>-0.753748</td>\n",
       "      <td>-0.795194</td>\n",
       "      <td>0.448189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>-0.128607</td>\n",
       "      <td>-0.743650</td>\n",
       "      <td>-0.051193</td>\n",
       "      <td>0.445601</td>\n",
       "      <td>-0.079883</td>\n",
       "      <td>0.350535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-0.497211</td>\n",
       "      <td>-0.249103</td>\n",
       "      <td>0.494119</td>\n",
       "      <td>0.306849</td>\n",
       "      <td>0.333390</td>\n",
       "      <td>-0.333267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-0.431120</td>\n",
       "      <td>-0.198486</td>\n",
       "      <td>-0.933028</td>\n",
       "      <td>-0.042925</td>\n",
       "      <td>0.840569</td>\n",
       "      <td>-0.283434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.552343</td>\n",
       "      <td>-0.781929</td>\n",
       "      <td>0.848421</td>\n",
       "      <td>-0.143265</td>\n",
       "      <td>-0.982400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-0.061408</td>\n",
       "      <td>0.668209</td>\n",
       "      <td>0.463380</td>\n",
       "      <td>0.632308</td>\n",
       "      <td>0.696893</td>\n",
       "      <td>0.448758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.915210</td>\n",
       "      <td>0.366108</td>\n",
       "      <td>0.738329</td>\n",
       "      <td>0.774137</td>\n",
       "      <td>0.432964</td>\n",
       "      <td>-0.947602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.289174</td>\n",
       "      <td>0.646266</td>\n",
       "      <td>-0.392641</td>\n",
       "      <td>0.408150</td>\n",
       "      <td>-0.041150</td>\n",
       "      <td>0.304168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>-0.094014</td>\n",
       "      <td>-0.843747</td>\n",
       "      <td>-0.183394</td>\n",
       "      <td>0.727780</td>\n",
       "      <td>-0.423013</td>\n",
       "      <td>-0.582346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.042362</td>\n",
       "      <td>0.558212</td>\n",
       "      <td>-0.729278</td>\n",
       "      <td>-0.756072</td>\n",
       "      <td>0.156956</td>\n",
       "      <td>0.088016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>-0.956073</td>\n",
       "      <td>0.790813</td>\n",
       "      <td>-0.322825</td>\n",
       "      <td>0.892988</td>\n",
       "      <td>0.824058</td>\n",
       "      <td>0.983150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.675481</td>\n",
       "      <td>0.931762</td>\n",
       "      <td>0.739770</td>\n",
       "      <td>0.721478</td>\n",
       "      <td>0.249020</td>\n",
       "      <td>-0.849595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>-0.120849</td>\n",
       "      <td>0.935578</td>\n",
       "      <td>-0.228616</td>\n",
       "      <td>0.548055</td>\n",
       "      <td>-0.615220</td>\n",
       "      <td>0.734589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.071055</td>\n",
       "      <td>-0.796098</td>\n",
       "      <td>0.690087</td>\n",
       "      <td>0.363349</td>\n",
       "      <td>0.045684</td>\n",
       "      <td>0.920648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.617073</td>\n",
       "      <td>-0.698139</td>\n",
       "      <td>-0.966767</td>\n",
       "      <td>-0.316545</td>\n",
       "      <td>-0.117173</td>\n",
       "      <td>0.167011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>-0.647717</td>\n",
       "      <td>0.930848</td>\n",
       "      <td>0.686729</td>\n",
       "      <td>0.408145</td>\n",
       "      <td>-0.962925</td>\n",
       "      <td>-0.529513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.434472</td>\n",
       "      <td>0.326745</td>\n",
       "      <td>0.340639</td>\n",
       "      <td>-0.187349</td>\n",
       "      <td>-0.810688</td>\n",
       "      <td>0.312732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.475607</td>\n",
       "      <td>0.041404</td>\n",
       "      <td>-0.498867</td>\n",
       "      <td>-0.162485</td>\n",
       "      <td>0.101696</td>\n",
       "      <td>-0.893341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>-0.476702</td>\n",
       "      <td>-0.533395</td>\n",
       "      <td>0.369784</td>\n",
       "      <td>-0.923992</td>\n",
       "      <td>0.980186</td>\n",
       "      <td>-0.653787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.518213</td>\n",
       "      <td>-0.626250</td>\n",
       "      <td>0.283820</td>\n",
       "      <td>-0.298882</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.538211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>-0.844655</td>\n",
       "      <td>0.626744</td>\n",
       "      <td>0.295543</td>\n",
       "      <td>0.525907</td>\n",
       "      <td>0.545653</td>\n",
       "      <td>0.187515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.493339</td>\n",
       "      <td>-0.993304</td>\n",
       "      <td>-0.425464</td>\n",
       "      <td>0.861137</td>\n",
       "      <td>-0.472340</td>\n",
       "      <td>-0.630433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.530020</td>\n",
       "      <td>-0.387536</td>\n",
       "      <td>0.798316</td>\n",
       "      <td>0.299575</td>\n",
       "      <td>0.064211</td>\n",
       "      <td>-0.214456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.787311</td>\n",
       "      <td>0.562813</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.718761</td>\n",
       "      <td>0.863440</td>\n",
       "      <td>-0.889987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          H0        H1        H2        H3        H4        H5\n",
       "0   0.727830 -0.093690  0.655824  0.475866  0.248253 -0.866811\n",
       "1   0.321437  0.107595  0.391856 -0.359392 -0.520064  0.142841\n",
       "2   0.689415 -0.463203 -0.398532 -0.590082 -0.424747  0.738922\n",
       "3   0.523500 -0.889057 -0.887992  0.032942  0.556211 -0.907647\n",
       "4  -0.369475  1.086272 -0.189472 -0.229899  0.880091  0.138221\n",
       "5   0.705245  0.314280 -0.602125 -0.163876 -0.127460  0.318749\n",
       "6   0.313449 -0.319188  0.393496 -0.150507  0.958900 -0.217146\n",
       "7   0.636164  0.478594  0.170882 -0.102815 -0.218526  0.711031\n",
       "8  -0.928013 -0.705388  0.120532 -0.311802  0.484095  0.571152\n",
       "9   0.043885  0.385562  0.520521 -0.551962  0.607191  1.017549\n",
       "10  0.397304  0.254821 -0.010637 -0.254493  0.669858 -0.765313\n",
       "11  0.180043 -0.078013  0.505823  0.133150  0.991329  0.696982\n",
       "12 -0.656112 -0.620301 -0.709265  0.746427  0.018501 -0.234816\n",
       "13  0.259179 -0.013432 -0.451791 -0.974484  0.110646  0.220679\n",
       "14 -0.635378  0.419068 -0.179007  0.123692 -0.226800 -0.107155\n",
       "15  0.235748 -0.568458  0.952271  0.730605  0.183998  0.633529\n",
       "16  0.504899 -0.795931  0.751330  0.252495 -0.765721  0.524133\n",
       "17 -0.783042  0.392692 -0.716904  1.010787 -0.731890 -0.350400\n",
       "18  0.943952  0.562015  0.578610  0.540053 -0.462542 -0.323191\n",
       "19 -0.824633  0.696988 -0.172379 -0.184408 -0.770429 -0.313344\n",
       "20  0.344167 -0.437932 -0.704223 -0.266585 -0.153177  0.593064\n",
       "21 -0.479980 -0.728525 -0.656501 -0.292995 -0.297009  0.173929\n",
       "22  0.083691 -0.061719 -0.625580  0.527606 -0.935239  0.023308\n",
       "23  0.842410 -0.870627  0.822385 -0.364894 -0.462404  0.791827\n",
       "24  0.877534  0.248454 -0.121570 -0.068822 -0.624394 -0.018862\n",
       "25  0.821572 -0.210462 -0.951576  0.948031 -0.494482  0.648225\n",
       "26  0.794477 -0.478061 -0.640292 -0.493687  0.231146 -0.966012\n",
       "27  0.654781  0.058267 -0.005305 -0.607076  0.176765  0.595535\n",
       "28  0.457523 -0.072305  0.613825  0.692523 -0.680311 -0.061927\n",
       "29  0.561883  0.721890  0.463784  0.250419 -0.733999 -0.744628\n",
       "..       ...       ...       ...       ...       ...       ...\n",
       "60 -0.428041  0.366194 -0.717949 -0.597317 -0.741615 -0.184528\n",
       "61  0.212251 -0.014340 -0.707085  0.659017  0.315312  0.721877\n",
       "62  0.138740 -0.592313 -0.089485 -0.655792  0.862211 -0.778296\n",
       "63  0.565427 -0.557896  0.843607  0.360004  0.434357  0.896779\n",
       "64  0.264830  0.055051  0.577843 -0.157622 -0.638294 -0.959093\n",
       "65  0.520603  0.274520 -0.333823  0.743839  0.213099 -0.088835\n",
       "66 -0.479485 -0.057888 -0.855119 -0.753748 -0.795194  0.448189\n",
       "67 -0.128607 -0.743650 -0.051193  0.445601 -0.079883  0.350535\n",
       "68 -0.497211 -0.249103  0.494119  0.306849  0.333390 -0.333267\n",
       "69 -0.431120 -0.198486 -0.933028 -0.042925  0.840569 -0.283434\n",
       "70  0.061540  0.552343 -0.781929  0.848421 -0.143265 -0.982400\n",
       "71 -0.061408  0.668209  0.463380  0.632308  0.696893  0.448758\n",
       "72  0.915210  0.366108  0.738329  0.774137  0.432964 -0.947602\n",
       "73  0.289174  0.646266 -0.392641  0.408150 -0.041150  0.304168\n",
       "74 -0.094014 -0.843747 -0.183394  0.727780 -0.423013 -0.582346\n",
       "75  0.042362  0.558212 -0.729278 -0.756072  0.156956  0.088016\n",
       "76 -0.956073  0.790813 -0.322825  0.892988  0.824058  0.983150\n",
       "77  0.675481  0.931762  0.739770  0.721478  0.249020 -0.849595\n",
       "78 -0.120849  0.935578 -0.228616  0.548055 -0.615220  0.734589\n",
       "79  0.071055 -0.796098  0.690087  0.363349  0.045684  0.920648\n",
       "80  0.617073 -0.698139 -0.966767 -0.316545 -0.117173  0.167011\n",
       "81 -0.647717  0.930848  0.686729  0.408145 -0.962925 -0.529513\n",
       "82  0.434472  0.326745  0.340639 -0.187349 -0.810688  0.312732\n",
       "83  0.475607  0.041404 -0.498867 -0.162485  0.101696 -0.893341\n",
       "84 -0.476702 -0.533395  0.369784 -0.923992  0.980186 -0.653787\n",
       "85  0.518213 -0.626250  0.283820 -0.298882  0.000551  0.538211\n",
       "86 -0.844655  0.626744  0.295543  0.525907  0.545653  0.187515\n",
       "87  0.493339 -0.993304 -0.425464  0.861137 -0.472340 -0.630433\n",
       "88  0.530020 -0.387536  0.798316  0.299575  0.064211 -0.214456\n",
       "89  0.787311  0.562813  0.465116  0.718761  0.863440 -0.889987\n",
       "\n",
       "[90 rows x 6 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrames for the final weights going into and out of each hidden node\n",
    "\n",
    "HiddenToOutputFinalWeights = pd.DataFrame([vWeightArrayPost[0]\n",
    "                                          ,vWeightArrayPost[1]\n",
    "                                          ,vWeightArrayPost[2]\n",
    "                                          ,vWeightArrayPost[3]\n",
    "                                          ,vWeightArrayPost[4]\n",
    "                                          ,vWeightArrayPost[5]\n",
    "                                          ,vWeightArrayPost[6]\n",
    "                                          ,vWeightArrayPost[7]\n",
    "                                          ,vWeightArrayPost[8]\n",
    "                                          ], columns = [\"H0\", \"H1\", \"H2\", \"H3\"\n",
    "                                                       ,\"H4\",\"H5\"]\n",
    "                                         , index = [\"o0\", \"o1\", \"o2\", \"o3\", \"o4\"\n",
    "                                                   , \"o5\", \"o6\", \"o7\", \"o8\"])\n",
    "HiddenToOutputFinalWeights = HiddenToOutputFinalWeights.transpose()\n",
    "HiddenToOutputFinalWeights\n",
    "\n",
    "InputToHiddenFinalWeights = pd.DataFrame([wWeightArrayPost[0]\n",
    "                                          ,wWeightArrayPost[1]\n",
    "                                          ,wWeightArrayPost[2]\n",
    "                                          ,wWeightArrayPost[3]\n",
    "                                          ,wWeightArrayPost[4]\n",
    "                                          ,wWeightArrayPost[5]]\n",
    "                                          , index = [\"H0\", \"H1\", \"H2\", \"H3\"\n",
    "                                                       ,\"H4\",\"H5\"])\n",
    "InputToHiddenFinalWeights = InputToHiddenFinalWeights.transpose()\n",
    "\n",
    "InputToHiddenFinalWeights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R1BDnz6jFWfT"
   },
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rB9jEjxyFrBt"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "qHFODzRjz6Qh",
    "outputId": "dc324485-3188-4fd9-e805-aea262fc861f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>o0</th>\n",
       "      <th>o1</th>\n",
       "      <th>o2</th>\n",
       "      <th>o3</th>\n",
       "      <th>o4</th>\n",
       "      <th>o5</th>\n",
       "      <th>o6</th>\n",
       "      <th>o7</th>\n",
       "      <th>o8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>H0</th>\n",
       "      <td>-140.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-104.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-114.0</td>\n",
       "      <td>-278.0</td>\n",
       "      <td>-134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H1</th>\n",
       "      <td>-462.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>-153.0</td>\n",
       "      <td>-250.0</td>\n",
       "      <td>-116.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-88.0</td>\n",
       "      <td>-143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H2</th>\n",
       "      <td>90.0</td>\n",
       "      <td>-195.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>-261.0</td>\n",
       "      <td>-115.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H3</th>\n",
       "      <td>-289.0</td>\n",
       "      <td>-390.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>-641.0</td>\n",
       "      <td>-468.0</td>\n",
       "      <td>-551.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H4</th>\n",
       "      <td>-53.0</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>-329.0</td>\n",
       "      <td>-408.0</td>\n",
       "      <td>-214.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>-299.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H5</th>\n",
       "      <td>-344.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>-731.0</td>\n",
       "      <td>-682.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>-1147.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       o0     o1     o2     o3     o4     o5     o6     o7      o8\n",
       "H0 -140.0  -18.0 -104.0  -35.0   86.0 -163.0 -114.0 -278.0  -134.0\n",
       "H1 -462.0  136.0  173.0 -153.0 -250.0 -116.0    3.0  -88.0  -143.0\n",
       "H2   90.0 -195.0 -185.0  -63.0 -261.0 -115.0  131.0 -224.0   -78.0\n",
       "H3 -289.0 -390.0  386.0  363.0 -641.0 -468.0 -551.0  531.0   159.0\n",
       "H4  -53.0  -65.0 -329.0 -408.0 -214.0  191.0 -299.0   37.0   240.0\n",
       "H5 -344.0  104.0 -731.0 -682.0  673.0  191.0  284.0  753.0 -1147.0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HiddenToOutputWeightIndex = round(HiddenToOutputFinalWeights.div(HiddenToOutputFinalWeights.mean(axis=1), axis = 0)*-100,0)\n",
    "HiddenToOutputWeightIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "662vkGIJ2kZc"
   },
   "outputs": [],
   "source": [
    "HiddenToOutputWeightIndex.to_csv(\"HiddenToOutPutIndex.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H0</th>\n",
       "      <th>H1</th>\n",
       "      <th>H2</th>\n",
       "      <th>H3</th>\n",
       "      <th>H4</th>\n",
       "      <th>H5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.071905</td>\n",
       "      <td>0.933850</td>\n",
       "      <td>0.648019</td>\n",
       "      <td>0.592283</td>\n",
       "      <td>0.930078</td>\n",
       "      <td>0.161622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.987198</td>\n",
       "      <td>0.997384</td>\n",
       "      <td>0.734167</td>\n",
       "      <td>0.906111</td>\n",
       "      <td>0.994349</td>\n",
       "      <td>0.178250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.988546</td>\n",
       "      <td>0.951340</td>\n",
       "      <td>0.888576</td>\n",
       "      <td>0.870621</td>\n",
       "      <td>0.991797</td>\n",
       "      <td>0.925278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.977649</td>\n",
       "      <td>0.987876</td>\n",
       "      <td>0.913936</td>\n",
       "      <td>0.944549</td>\n",
       "      <td>0.992755</td>\n",
       "      <td>0.768433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>0.973210</td>\n",
       "      <td>0.827646</td>\n",
       "      <td>0.903638</td>\n",
       "      <td>0.578124</td>\n",
       "      <td>0.995750</td>\n",
       "      <td>0.843919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>0.955492</td>\n",
       "      <td>0.516175</td>\n",
       "      <td>0.974245</td>\n",
       "      <td>0.093362</td>\n",
       "      <td>0.995332</td>\n",
       "      <td>0.480804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>0.986526</td>\n",
       "      <td>0.994577</td>\n",
       "      <td>0.911542</td>\n",
       "      <td>0.829218</td>\n",
       "      <td>0.996248</td>\n",
       "      <td>0.894454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H</th>\n",
       "      <td>0.291481</td>\n",
       "      <td>0.711749</td>\n",
       "      <td>0.981757</td>\n",
       "      <td>0.565161</td>\n",
       "      <td>0.988027</td>\n",
       "      <td>0.114669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>0.930698</td>\n",
       "      <td>0.935915</td>\n",
       "      <td>0.275890</td>\n",
       "      <td>0.974657</td>\n",
       "      <td>0.912053</td>\n",
       "      <td>0.223865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J</th>\n",
       "      <td>0.344047</td>\n",
       "      <td>0.942724</td>\n",
       "      <td>0.269281</td>\n",
       "      <td>0.990812</td>\n",
       "      <td>0.947719</td>\n",
       "      <td>0.658388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K</th>\n",
       "      <td>0.973417</td>\n",
       "      <td>0.658617</td>\n",
       "      <td>0.986339</td>\n",
       "      <td>0.984710</td>\n",
       "      <td>0.986229</td>\n",
       "      <td>0.033409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L</th>\n",
       "      <td>0.955230</td>\n",
       "      <td>0.948075</td>\n",
       "      <td>0.977577</td>\n",
       "      <td>0.982857</td>\n",
       "      <td>0.964013</td>\n",
       "      <td>0.681271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>0.642825</td>\n",
       "      <td>0.643843</td>\n",
       "      <td>0.971086</td>\n",
       "      <td>0.867616</td>\n",
       "      <td>0.963423</td>\n",
       "      <td>0.257323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.772966</td>\n",
       "      <td>0.897780</td>\n",
       "      <td>0.853483</td>\n",
       "      <td>0.923363</td>\n",
       "      <td>0.987862</td>\n",
       "      <td>0.069605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>0.922114</td>\n",
       "      <td>0.978868</td>\n",
       "      <td>0.850977</td>\n",
       "      <td>0.619139</td>\n",
       "      <td>0.993658</td>\n",
       "      <td>0.961941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>0.948887</td>\n",
       "      <td>0.582835</td>\n",
       "      <td>0.958795</td>\n",
       "      <td>0.292367</td>\n",
       "      <td>0.991365</td>\n",
       "      <td>0.239038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         H0        H1        H2        H3        H4        H5\n",
       "A  0.071905  0.933850  0.648019  0.592283  0.930078  0.161622\n",
       "B  0.987198  0.997384  0.734167  0.906111  0.994349  0.178250\n",
       "C  0.988546  0.951340  0.888576  0.870621  0.991797  0.925278\n",
       "D  0.977649  0.987876  0.913936  0.944549  0.992755  0.768433\n",
       "E  0.973210  0.827646  0.903638  0.578124  0.995750  0.843919\n",
       "F  0.955492  0.516175  0.974245  0.093362  0.995332  0.480804\n",
       "G  0.986526  0.994577  0.911542  0.829218  0.996248  0.894454\n",
       "H  0.291481  0.711749  0.981757  0.565161  0.988027  0.114669\n",
       "I  0.930698  0.935915  0.275890  0.974657  0.912053  0.223865\n",
       "J  0.344047  0.942724  0.269281  0.990812  0.947719  0.658388\n",
       "K  0.973417  0.658617  0.986339  0.984710  0.986229  0.033409\n",
       "L  0.955230  0.948075  0.977577  0.982857  0.964013  0.681271\n",
       "M  0.642825  0.643843  0.971086  0.867616  0.963423  0.257323\n",
       "N  0.772966  0.897780  0.853483  0.923363  0.987862  0.069605\n",
       "O  0.922114  0.978868  0.850977  0.619139  0.993658  0.961941\n",
       "P  0.948887  0.582835  0.958795  0.292367  0.991365  0.239038"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postHidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>o0</th>\n",
       "      <th>o1</th>\n",
       "      <th>o2</th>\n",
       "      <th>o3</th>\n",
       "      <th>o4</th>\n",
       "      <th>o5</th>\n",
       "      <th>o6</th>\n",
       "      <th>o7</th>\n",
       "      <th>o8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.178983</td>\n",
       "      <td>0.211060</td>\n",
       "      <td>0.235630</td>\n",
       "      <td>0.233424</td>\n",
       "      <td>0.090310</td>\n",
       "      <td>0.287259</td>\n",
       "      <td>0.170845</td>\n",
       "      <td>0.178463</td>\n",
       "      <td>0.255473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.095766</td>\n",
       "      <td>0.165006</td>\n",
       "      <td>0.181936</td>\n",
       "      <td>0.213898</td>\n",
       "      <td>0.078448</td>\n",
       "      <td>0.148012</td>\n",
       "      <td>0.095216</td>\n",
       "      <td>0.082904</td>\n",
       "      <td>0.178625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.087250</td>\n",
       "      <td>0.156707</td>\n",
       "      <td>0.100037</td>\n",
       "      <td>0.138653</td>\n",
       "      <td>0.109530</td>\n",
       "      <td>0.160257</td>\n",
       "      <td>0.127018</td>\n",
       "      <td>0.115114</td>\n",
       "      <td>0.083980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.086048</td>\n",
       "      <td>0.148514</td>\n",
       "      <td>0.114622</td>\n",
       "      <td>0.153151</td>\n",
       "      <td>0.088884</td>\n",
       "      <td>0.147637</td>\n",
       "      <td>0.118266</td>\n",
       "      <td>0.107234</td>\n",
       "      <td>0.098031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>0.118387</td>\n",
       "      <td>0.168984</td>\n",
       "      <td>0.084829</td>\n",
       "      <td>0.133068</td>\n",
       "      <td>0.140855</td>\n",
       "      <td>0.193831</td>\n",
       "      <td>0.153530</td>\n",
       "      <td>0.092379</td>\n",
       "      <td>0.090618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>0.231293</td>\n",
       "      <td>0.174935</td>\n",
       "      <td>0.068390</td>\n",
       "      <td>0.146917</td>\n",
       "      <td>0.191117</td>\n",
       "      <td>0.253777</td>\n",
       "      <td>0.201846</td>\n",
       "      <td>0.053022</td>\n",
       "      <td>0.130578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>0.085271</td>\n",
       "      <td>0.159014</td>\n",
       "      <td>0.099938</td>\n",
       "      <td>0.134653</td>\n",
       "      <td>0.105105</td>\n",
       "      <td>0.160067</td>\n",
       "      <td>0.130992</td>\n",
       "      <td>0.106630</td>\n",
       "      <td>0.084078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H</th>\n",
       "      <td>0.235797</td>\n",
       "      <td>0.151183</td>\n",
       "      <td>0.153279</td>\n",
       "      <td>0.219822</td>\n",
       "      <td>0.075887</td>\n",
       "      <td>0.249121</td>\n",
       "      <td>0.178222</td>\n",
       "      <td>0.109062</td>\n",
       "      <td>0.245916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>0.087794</td>\n",
       "      <td>0.221843</td>\n",
       "      <td>0.261369</td>\n",
       "      <td>0.264351</td>\n",
       "      <td>0.133315</td>\n",
       "      <td>0.176763</td>\n",
       "      <td>0.078291</td>\n",
       "      <td>0.144086</td>\n",
       "      <td>0.197818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J</th>\n",
       "      <td>0.101945</td>\n",
       "      <td>0.235736</td>\n",
       "      <td>0.247251</td>\n",
       "      <td>0.220724</td>\n",
       "      <td>0.137951</td>\n",
       "      <td>0.257093</td>\n",
       "      <td>0.106462</td>\n",
       "      <td>0.312688</td>\n",
       "      <td>0.178346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K</th>\n",
       "      <td>0.163626</td>\n",
       "      <td>0.114638</td>\n",
       "      <td>0.149599</td>\n",
       "      <td>0.256248</td>\n",
       "      <td>0.065145</td>\n",
       "      <td>0.137747</td>\n",
       "      <td>0.100444</td>\n",
       "      <td>0.069335</td>\n",
       "      <td>0.216544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L</th>\n",
       "      <td>0.095388</td>\n",
       "      <td>0.136779</td>\n",
       "      <td>0.119367</td>\n",
       "      <td>0.168896</td>\n",
       "      <td>0.079298</td>\n",
       "      <td>0.139942</td>\n",
       "      <td>0.120402</td>\n",
       "      <td>0.101140</td>\n",
       "      <td>0.106322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>0.189969</td>\n",
       "      <td>0.127811</td>\n",
       "      <td>0.142851</td>\n",
       "      <td>0.234026</td>\n",
       "      <td>0.077104</td>\n",
       "      <td>0.182920</td>\n",
       "      <td>0.132948</td>\n",
       "      <td>0.105637</td>\n",
       "      <td>0.200523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.129856</td>\n",
       "      <td>0.145181</td>\n",
       "      <td>0.186254</td>\n",
       "      <td>0.236803</td>\n",
       "      <td>0.063957</td>\n",
       "      <td>0.158378</td>\n",
       "      <td>0.107170</td>\n",
       "      <td>0.089308</td>\n",
       "      <td>0.216057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>0.093381</td>\n",
       "      <td>0.184055</td>\n",
       "      <td>0.092015</td>\n",
       "      <td>0.121685</td>\n",
       "      <td>0.136850</td>\n",
       "      <td>0.193711</td>\n",
       "      <td>0.152902</td>\n",
       "      <td>0.109169</td>\n",
       "      <td>0.079544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>0.213897</td>\n",
       "      <td>0.162018</td>\n",
       "      <td>0.093035</td>\n",
       "      <td>0.179593</td>\n",
       "      <td>0.140079</td>\n",
       "      <td>0.219186</td>\n",
       "      <td>0.168039</td>\n",
       "      <td>0.052145</td>\n",
       "      <td>0.166737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         o0        o1        o2        o3        o4        o5        o6  \\\n",
       "A  0.178983  0.211060  0.235630  0.233424  0.090310  0.287259  0.170845   \n",
       "B  0.095766  0.165006  0.181936  0.213898  0.078448  0.148012  0.095216   \n",
       "C  0.087250  0.156707  0.100037  0.138653  0.109530  0.160257  0.127018   \n",
       "D  0.086048  0.148514  0.114622  0.153151  0.088884  0.147637  0.118266   \n",
       "E  0.118387  0.168984  0.084829  0.133068  0.140855  0.193831  0.153530   \n",
       "F  0.231293  0.174935  0.068390  0.146917  0.191117  0.253777  0.201846   \n",
       "G  0.085271  0.159014  0.099938  0.134653  0.105105  0.160067  0.130992   \n",
       "H  0.235797  0.151183  0.153279  0.219822  0.075887  0.249121  0.178222   \n",
       "I  0.087794  0.221843  0.261369  0.264351  0.133315  0.176763  0.078291   \n",
       "J  0.101945  0.235736  0.247251  0.220724  0.137951  0.257093  0.106462   \n",
       "K  0.163626  0.114638  0.149599  0.256248  0.065145  0.137747  0.100444   \n",
       "L  0.095388  0.136779  0.119367  0.168896  0.079298  0.139942  0.120402   \n",
       "M  0.189969  0.127811  0.142851  0.234026  0.077104  0.182920  0.132948   \n",
       "N  0.129856  0.145181  0.186254  0.236803  0.063957  0.158378  0.107170   \n",
       "O  0.093381  0.184055  0.092015  0.121685  0.136850  0.193711  0.152902   \n",
       "P  0.213897  0.162018  0.093035  0.179593  0.140079  0.219186  0.168039   \n",
       "\n",
       "         o7        o8  \n",
       "A  0.178463  0.255473  \n",
       "B  0.082904  0.178625  \n",
       "C  0.115114  0.083980  \n",
       "D  0.107234  0.098031  \n",
       "E  0.092379  0.090618  \n",
       "F  0.053022  0.130578  \n",
       "G  0.106630  0.084078  \n",
       "H  0.109062  0.245916  \n",
       "I  0.144086  0.197818  \n",
       "J  0.312688  0.178346  \n",
       "K  0.069335  0.216544  \n",
       "L  0.101140  0.106322  \n",
       "M  0.105637  0.200523  \n",
       "N  0.089308  0.216057  \n",
       "O  0.109169  0.079544  \n",
       "P  0.052145  0.166737  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desiredOutputPost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Classifier NN Working Code",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
